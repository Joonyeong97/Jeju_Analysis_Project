{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kor_jeju.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEIky_zshPjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://neurowhai.tistory.com/292"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa4IReo6Cc7a",
        "colab_type": "code",
        "outputId": "686f61e0-9abf-499a-c8d6-73dd43f1dbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "device_lib.list_local_devices()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 3876883829019089860, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 5933003659533636849\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 12620358854082576940\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 11978132078730237417\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNlo6VGXFllH",
        "colab_type": "code",
        "outputId": "8501afe3-ece9-44c0-9cff-940bfa77887b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xGdGylMFawA",
        "colab_type": "code",
        "outputId": "6815c952-fc87-44bb-d68c-b3d4c8616657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Q2fuUMCOaO",
        "colab_type": "code",
        "outputId": "845355f9-f2f9-4e82-8b1f-548dcac4eac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import matplotlib\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = '/content/dataset.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def RepeatVectorLayer(rep, axis):\n",
        "  return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis),\n",
        "                      lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n",
        "\n",
        "\n",
        "# 인코더 생성\n",
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "# 디코더 생성\n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n",
        "decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
        "\n",
        "# attention 생성\n",
        "'''\n",
        "어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, \n",
        "인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. \n",
        "단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, \n",
        "해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 \n",
        "집중(attention)해서 보게 됩니다.\n",
        "'''\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "# 입력을 n 번 반복합니다.\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "# 입력을 n 번 반복합니다.\n",
        "repeat_e = repeat_e_layer(encoder_outputs)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "#layers.Concatenate는 입력 목록을 연결하는 계층입니다.\n",
        "# 연결 축을 제외하고 모두 동일한 모양의 텐서 목록을 입력으로 사용하고 \n",
        "# 모든 입력의 연결 인 단일 텐서를 반환합니다.\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh')\n",
        "# Dense 클래스 객체를 TimeDistributed wrapper를 사용하여 3차원 텐서 입력을 받을 수 있게 확장\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "\n",
        "dense2_t_score_layer = layers.Dense(1)\n",
        "# Dense 클래스 객체를 TimeDistributed wrapper를 사용하여 3차원 텐서 입력을 받을 수 있게 확장\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "# soft max 설정\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "# 입력을 n 번 반복합니다 RepeatVectorLayer\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "# layers.Permute 주어진 패턴에 따라 입력 치수를 변경합니다.\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs)\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply() # 행렬곱\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "'''입력 목록을 연결하는 계층입니다.\n",
        "연결 축을 제외하고 모두 동일한 모양의 텐서 목록을 입력으로 \n",
        "사용하고 모든 입력의 연결 인 단일 텐서를 반환합니다.'''\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh')\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(attention_output)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "che = 'atten_GRU_weight_g.h5'\n",
        "point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1,callbacks=[point,early_stopping])\n",
        "# Save model\n",
        "model.save('atten_GRU_weight.h5')\n",
        "# \n",
        "\n",
        "\n",
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) encode input and retrieve initial decoder state\n",
        "# 2) run one step of decoder with this initial state\n",
        "# and a \"start of sequence\" token as target.\n",
        "# Output will be the next target token\n",
        "# 3) Repeat with the current target token and current states\n",
        "\n",
        "# Define sampling models\n",
        "encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h])\n",
        "encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim))\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(1, num_decoder_tokens))\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h)\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs_input)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_att_outputs = decoder_dense(attention_output)\n",
        "\n",
        "decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input],\n",
        "                            [decoder_outputs, decoder_h, decoder_att_outputs])\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # 입력 문장을 인코딩\n",
        "  enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "  # 디코더의 입력으로 쓸 단일 문자\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "  # 문장 생성\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "    # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "    dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "        [target_seq, states_value, enc_outputs])\n",
        " \n",
        "    # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        " \n",
        "    # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        " \n",
        "    # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    states_value = h\n",
        " \n",
        "  return decoded_sentence\n",
        "\n",
        "for seq_index in range(30):\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1203\n",
            "Number of unique input tokens: 787\n",
            "Number of unique output tokens: 749\n",
            "Max sequence length for inputs: 165\n",
            "Max sequence length for outputs: 183\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 962 samples, validate on 241 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "962/962 [==============================] - 22s 23ms/step - loss: 0.3446 - acc: 0.0125 - val_loss: 0.5602 - val_acc: 0.0270\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.56024, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 2/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.3058 - acc: 0.0141 - val_loss: 0.5371 - val_acc: 0.0279\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.56024 to 0.53709, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 3/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.2911 - acc: 0.0152 - val_loss: 0.5087 - val_acc: 0.0284\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.53709 to 0.50866, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 4/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.2774 - acc: 0.0167 - val_loss: 0.4935 - val_acc: 0.0287\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.50866 to 0.49350, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 5/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.2668 - acc: 0.0185 - val_loss: 0.4723 - val_acc: 0.0305\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.49350 to 0.47227, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 6/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.2581 - acc: 0.0197 - val_loss: 0.4560 - val_acc: 0.0331\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.47227 to 0.45598, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 7/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.2502 - acc: 0.0206 - val_loss: 0.4476 - val_acc: 0.0350\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.45598 to 0.44758, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 8/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.2429 - acc: 0.0217 - val_loss: 0.4387 - val_acc: 0.0383\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.44758 to 0.43871, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 9/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.2360 - acc: 0.0227 - val_loss: 0.4266 - val_acc: 0.0415\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.43871 to 0.42660, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 10/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.2290 - acc: 0.0235 - val_loss: 0.4352 - val_acc: 0.0388\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.42660\n",
            "Epoch 11/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.2222 - acc: 0.0247 - val_loss: 0.4233 - val_acc: 0.0424\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.42660 to 0.42329, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 12/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.2207 - acc: 0.0253 - val_loss: 0.4309 - val_acc: 0.0395\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.42329\n",
            "Epoch 13/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.2099 - acc: 0.0262 - val_loss: 0.4237 - val_acc: 0.0426\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.42329\n",
            "Epoch 14/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.2039 - acc: 0.0272 - val_loss: 0.4201 - val_acc: 0.0429\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.42329 to 0.42007, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 15/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1981 - acc: 0.0279 - val_loss: 0.4156 - val_acc: 0.0447\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.42007 to 0.41560, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 16/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1925 - acc: 0.0288 - val_loss: 0.4154 - val_acc: 0.0445\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.41560 to 0.41537, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 17/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.1862 - acc: 0.0296 - val_loss: 0.4184 - val_acc: 0.0437\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.41537\n",
            "Epoch 18/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1801 - acc: 0.0311 - val_loss: 0.4082 - val_acc: 0.0455\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.41537 to 0.40822, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 19/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1744 - acc: 0.0317 - val_loss: 0.4128 - val_acc: 0.0461\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.40822\n",
            "Epoch 20/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.1687 - acc: 0.0326 - val_loss: 0.4101 - val_acc: 0.0463\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.40822\n",
            "Epoch 21/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1631 - acc: 0.0332 - val_loss: 0.4256 - val_acc: 0.0435\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.40822\n",
            "Epoch 22/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1575 - acc: 0.0343 - val_loss: 0.4086 - val_acc: 0.0467\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.40822\n",
            "Epoch 23/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.1521 - acc: 0.0353 - val_loss: 0.4357 - val_acc: 0.0435\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.40822\n",
            "Epoch 24/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1472 - acc: 0.0358 - val_loss: 0.4642 - val_acc: 0.0412\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.40822\n",
            "Epoch 25/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1418 - acc: 0.0369 - val_loss: 0.4357 - val_acc: 0.0446\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.40822\n",
            "Epoch 26/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1372 - acc: 0.0377 - val_loss: 0.4225 - val_acc: 0.0463\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.40822\n",
            "Epoch 27/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1326 - acc: 0.0387 - val_loss: 0.4286 - val_acc: 0.0458\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.40822\n",
            "Epoch 28/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.1270 - acc: 0.0394 - val_loss: 0.4591 - val_acc: 0.0440\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.40822\n",
            "Epoch 29/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1220 - acc: 0.0404 - val_loss: 0.4382 - val_acc: 0.0445\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.40822\n",
            "Epoch 30/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1178 - acc: 0.0411 - val_loss: 0.4347 - val_acc: 0.0474\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.40822\n",
            "Epoch 31/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1130 - acc: 0.0419 - val_loss: 0.4383 - val_acc: 0.0468\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.40822\n",
            "Epoch 32/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.1104 - acc: 0.0427 - val_loss: 0.4506 - val_acc: 0.0461\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.40822\n",
            "Epoch 33/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.1037 - acc: 0.0441 - val_loss: 0.4437 - val_acc: 0.0470\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.40822\n",
            "Epoch 34/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0991 - acc: 0.0448 - val_loss: 0.5080 - val_acc: 0.0399\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.40822\n",
            "Epoch 35/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0956 - acc: 0.0457 - val_loss: 0.5003 - val_acc: 0.0395\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.40822\n",
            "Epoch 36/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0913 - acc: 0.0467 - val_loss: 0.4605 - val_acc: 0.0457\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.40822\n",
            "Epoch 37/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0872 - acc: 0.0474 - val_loss: 0.4702 - val_acc: 0.0464\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.40822\n",
            "Epoch 38/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0834 - acc: 0.0484 - val_loss: 0.4717 - val_acc: 0.0455\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.40822\n",
            "Epoch 39/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0789 - acc: 0.0493 - val_loss: 0.4757 - val_acc: 0.0463\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.40822\n",
            "Epoch 40/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0750 - acc: 0.0504 - val_loss: 0.4957 - val_acc: 0.0447\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.40822\n",
            "Epoch 41/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0708 - acc: 0.0517 - val_loss: 0.4878 - val_acc: 0.0458\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.40822\n",
            "Epoch 42/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0673 - acc: 0.0522 - val_loss: 0.5204 - val_acc: 0.0409\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.40822\n",
            "Epoch 43/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0645 - acc: 0.0529 - val_loss: 0.4970 - val_acc: 0.0448\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.40822\n",
            "Epoch 44/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.0598 - acc: 0.0544 - val_loss: 0.5014 - val_acc: 0.0452\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.40822\n",
            "Epoch 45/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0567 - acc: 0.0548 - val_loss: 0.5218 - val_acc: 0.0428\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.40822\n",
            "Epoch 46/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0534 - acc: 0.0555 - val_loss: 0.5175 - val_acc: 0.0445\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.40822\n",
            "Epoch 47/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0500 - acc: 0.0565 - val_loss: 0.5521 - val_acc: 0.0441\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.40822\n",
            "Epoch 48/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0479 - acc: 0.0572 - val_loss: 0.5234 - val_acc: 0.0451\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.40822\n",
            "Epoch 49/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0438 - acc: 0.0582 - val_loss: 0.5648 - val_acc: 0.0415\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.40822\n",
            "Epoch 50/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0412 - acc: 0.0588 - val_loss: 0.5640 - val_acc: 0.0421\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.40822\n",
            "Epoch 51/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.0387 - acc: 0.0594 - val_loss: 0.5651 - val_acc: 0.0428\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.40822\n",
            "Epoch 52/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0395 - acc: 0.0591 - val_loss: 0.5539 - val_acc: 0.0441\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.40822\n",
            "Epoch 53/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0333 - acc: 0.0608 - val_loss: 0.5538 - val_acc: 0.0446\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.40822\n",
            "Epoch 54/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0321 - acc: 0.0609 - val_loss: 0.5924 - val_acc: 0.0417\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.40822\n",
            "Epoch 55/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0294 - acc: 0.0614 - val_loss: 0.5702 - val_acc: 0.0431\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.40822\n",
            "Epoch 56/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0275 - acc: 0.0621 - val_loss: 0.5803 - val_acc: 0.0430\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.40822\n",
            "Epoch 57/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0253 - acc: 0.0624 - val_loss: 0.5885 - val_acc: 0.0428\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.40822\n",
            "Epoch 58/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0235 - acc: 0.0629 - val_loss: 0.5868 - val_acc: 0.0436\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.40822\n",
            "Epoch 59/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0216 - acc: 0.0633 - val_loss: 0.5914 - val_acc: 0.0435\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.40822\n",
            "Epoch 60/100\n",
            "962/962 [==============================] - 20s 21ms/step - loss: 0.0202 - acc: 0.0636 - val_loss: 0.6144 - val_acc: 0.0415\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.40822\n",
            "Epoch 61/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0185 - acc: 0.0638 - val_loss: 0.6009 - val_acc: 0.0438\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.40822\n",
            "Epoch 62/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0176 - acc: 0.0641 - val_loss: 0.6130 - val_acc: 0.0430\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.40822\n",
            "Epoch 63/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0171 - acc: 0.0641 - val_loss: 0.6286 - val_acc: 0.0418\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.40822\n",
            "Epoch 64/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0140 - acc: 0.0649 - val_loss: 0.6282 - val_acc: 0.0427\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.40822\n",
            "Epoch 65/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0129 - acc: 0.0651 - val_loss: 0.6458 - val_acc: 0.0417\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.40822\n",
            "Epoch 66/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0123 - acc: 0.0652 - val_loss: 0.6251 - val_acc: 0.0442\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.40822\n",
            "Epoch 67/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0112 - acc: 0.0654 - val_loss: 0.6419 - val_acc: 0.0418\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.40822\n",
            "Epoch 68/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0105 - acc: 0.0655 - val_loss: 0.6383 - val_acc: 0.0422\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.40822\n",
            "Epoch 69/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0096 - acc: 0.0657 - val_loss: 0.6379 - val_acc: 0.0438\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.40822\n",
            "Epoch 70/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0084 - acc: 0.0659 - val_loss: 0.6436 - val_acc: 0.0441\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.40822\n",
            "Epoch 71/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0077 - acc: 0.0660 - val_loss: 0.6459 - val_acc: 0.0440\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.40822\n",
            "Epoch 72/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0075 - acc: 0.0660 - val_loss: 0.6525 - val_acc: 0.0442\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.40822\n",
            "Epoch 73/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0065 - acc: 0.0662 - val_loss: 0.6548 - val_acc: 0.0431\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.40822\n",
            "Epoch 74/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0061 - acc: 0.0662 - val_loss: 0.6529 - val_acc: 0.0432\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.40822\n",
            "Epoch 75/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0054 - acc: 0.0663 - val_loss: 0.6712 - val_acc: 0.0423\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.40822\n",
            "Epoch 76/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.0053 - acc: 0.0663 - val_loss: 0.6689 - val_acc: 0.0428\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.40822\n",
            "Epoch 77/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0049 - acc: 0.0663 - val_loss: 0.6915 - val_acc: 0.0421\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.40822\n",
            "Epoch 78/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0045 - acc: 0.0663 - val_loss: 0.6724 - val_acc: 0.0418\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.40822\n",
            "Epoch 79/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0040 - acc: 0.0664 - val_loss: 0.6852 - val_acc: 0.0442\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.40822\n",
            "Epoch 80/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0036 - acc: 0.0664 - val_loss: 0.6888 - val_acc: 0.0422\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.40822\n",
            "Epoch 81/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0033 - acc: 0.0665 - val_loss: 0.7125 - val_acc: 0.0403\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.40822\n",
            "Epoch 82/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0033 - acc: 0.0664 - val_loss: 0.6963 - val_acc: 0.0431\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.40822\n",
            "Epoch 83/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0031 - acc: 0.0665 - val_loss: 0.7037 - val_acc: 0.0417\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.40822\n",
            "Epoch 84/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0023 - acc: 0.0666 - val_loss: 0.7017 - val_acc: 0.0432\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.40822\n",
            "Epoch 85/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0026 - acc: 0.0665 - val_loss: 0.7096 - val_acc: 0.0435\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.40822\n",
            "Epoch 86/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0022 - acc: 0.0666 - val_loss: 0.7090 - val_acc: 0.0440\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.40822\n",
            "Epoch 87/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0022 - acc: 0.0665 - val_loss: 0.7023 - val_acc: 0.0426\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.40822\n",
            "Epoch 88/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0021 - acc: 0.0665 - val_loss: 0.7406 - val_acc: 0.0401\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.40822\n",
            "Epoch 89/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0023 - acc: 0.0664 - val_loss: 0.7024 - val_acc: 0.0439\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.40822\n",
            "Epoch 90/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0014 - acc: 0.0666 - val_loss: 0.7152 - val_acc: 0.0434\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.40822\n",
            "Epoch 91/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0017 - acc: 0.0665 - val_loss: 0.7173 - val_acc: 0.0437\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.40822\n",
            "Epoch 92/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0016 - acc: 0.0666 - val_loss: 0.7162 - val_acc: 0.0430\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.40822\n",
            "Epoch 93/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0021 - acc: 0.0664 - val_loss: 0.7115 - val_acc: 0.0442\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.40822\n",
            "Epoch 94/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.0012 - acc: 0.0666 - val_loss: 0.7120 - val_acc: 0.0441\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.40822\n",
            "Epoch 95/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0016 - acc: 0.0665 - val_loss: 0.7174 - val_acc: 0.0446\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.40822\n",
            "Epoch 96/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0016 - acc: 0.0665 - val_loss: 0.7264 - val_acc: 0.0440\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.40822\n",
            "Epoch 97/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0018 - acc: 0.0665 - val_loss: 0.7216 - val_acc: 0.0450\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.40822\n",
            "Epoch 98/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 8.8618e-04 - acc: 0.0666 - val_loss: 0.7442 - val_acc: 0.0425\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.40822\n",
            "Epoch 99/100\n",
            "962/962 [==============================] - 20s 20ms/step - loss: 0.0011 - acc: 0.0666 - val_loss: 0.7337 - val_acc: 0.0443\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.40822\n",
            "Epoch 100/100\n",
            "962/962 [==============================] - 19s 20ms/step - loss: 0.0012 - acc: 0.0666 - val_loss: 0.7437 - val_acc: 0.0434\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.40822\n",
            "\"버래기\" -> \"넘치도록\"\n",
            "\"강생이\" -> \"강아지\"\n",
            "\"부각허다\" -> \"부글부글하다\"\n",
            "\"강알\" -> \"가랭이\"\n",
            "\"부끄다\" -> \"부풀어 오르다\"\n",
            "\"개끔\" -> \"거품\"\n",
            "\"분시몰랑\" -> \"정황도 모르고\"\n",
            "\"개작개작\" -> \"밥을 추하게 먹는 모습\"\n",
            "\"삐암데기\" -> \"뺨\"\n",
            "\"검질\" -> \"잡초\"\n",
            "\"속슴허라\" -> \"말하지말라\"\n",
            "\"게미융허다\" -> \"희미하다\"\n",
            "\"솜쫄르멍\" -> \"숨말힐듯한 상황 참으면서\"\n",
            "\"게작헌\" -> \"입이 큰 모양\"\n",
            "\"쉰달이\" -> \"쉰 밥으로만든 유산식품\"\n",
            "\"고라불켜\" -> \"고자질한다\"\n",
            "\"심토맥이\" -> \"마음 씀씀이\"\n",
            "\"곡기다\" -> \"숨막히다\"\n",
            "\"영\" -> \"이렇게\"\n",
            "\"골다\" -> \"말하다\"\n",
            "\"골다\" -> \"말하다\"\n",
            "\"왁왁허다\" -> \"캄캄하다\"\n",
            "\"곱지다\" -> \"숨기다\"\n",
            "\"요망지다\" -> \"똑똑하다\"\n",
            "\"과랑과랑\" -> \"햇살이 눈부시게 비추는모습\"\n",
            "\"우영밭\" -> \"텃밭\"\n",
            "\"괸당\" -> \"친족\"\n",
            "\"웃뜨리\" -> \"산간마을\"\n",
            "\"굽\" -> \"밑바닥\"\n",
            "\"재짝재짝\" -> \"걷는 모습\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLhP5sLtVqWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kljrTUlxVqaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ5Sx8GZVq6T",
        "colab_type": "text"
      },
      "source": [
        "모델불러오고 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odtxgzYXVqey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7puwJOTU8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "fa1392db-3f23-46f0-d305-20c7686c4604"
      },
      "source": [
        "from keras.models import load_model\n",
        "history = load_model('/content/atten_GRU_weight_g.h5')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUL-DOIIU6zS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "9957facb-cc2b-4af7-869e-25d9f58f6d5d"
      },
      "source": [
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import matplotlib\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def RepeatVectorLayer(rep, axis):\n",
        "  return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis),\n",
        "                      lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n",
        "\n",
        "# 인코더 생성\n",
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "# 디코더 생성\n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n",
        "decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
        "\n",
        "# attention 생성\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh')\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "dense2_t_score_layer = layers.Dense(1)\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs)\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh')\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(attention_output)\n",
        "\n",
        "\n",
        "\n",
        "encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h])\n",
        "encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim))\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(1, num_decoder_tokens))\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h)\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs_input)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_att_outputs = decoder_dense(attention_output)\n",
        "\n",
        "decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input],\n",
        "                            [decoder_outputs, decoder_h, decoder_att_outputs])\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1203\n",
            "Number of unique input tokens: 787\n",
            "Number of unique output tokens: 749\n",
            "Max sequence length for inputs: 165\n",
            "Max sequence length for outputs: 183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDe7X2LKUonT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "fe6d1491-cc24-4607-c4d6-9098e1e55782"
      },
      "source": [
        "# def decode_sequence(input_seq):\n",
        "#   # 입력 문장을 인코딩\n",
        "#   enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "#   # 디코더의 입력으로 쓸 단일 문자\n",
        "#   target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#   # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "#   target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "#   # 문장 생성\n",
        "#   stop_condition = False\n",
        "#   decoded_sentence = ''\n",
        "#   while not stop_condition:\n",
        "#     # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "#     # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "#     dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "#         [target_seq, states_value, enc_outputs])\n",
        " \n",
        "#     # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "#     sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "#     sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "#     decoded_sentence += sampled_char\n",
        " \n",
        "#     # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "#     if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "#       stop_condition = True\n",
        " \n",
        "#     # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#     target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "#     states_value = h\n",
        " \n",
        "#   return decoded_sentence\n",
        "\n",
        "for seq_index in [550,600,512,523,566,855,745,654]:\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"아고 삼촌 물꾸럭 나 얼마마씸?\" -> \"아고 삼촌 문어 한마리 얼마죠?\"\n",
            "\"그짓말도 외삼춘 보다 낫나\" -> \"거짓말도 외삼촌 보다도 낫다.\"\n",
            "\"바당이영 춤을 추엄쩌\" -> \"바다와 춤을 추네\"\n",
            "\"덜 요문 조코 고리\" -> \"덜 익은 조 열매가\"\n",
            "\"각시 아꼬우민 처갯 칩 몰팡 돌에 절혼다.\" -> \"아내 아까우면 처가 집에 절한다.\"\n",
            "\"`먹돌도 똘람 시민 고망이 난다. 햄시민 된다.`\" -> \"`차돌도 뚫고 있으면 구멍이 난다. 하고 있으면 된다.`\"\n",
            "\"맨드롱 했수꽈?\" -> \"따뜻합니까?\"\n",
            "\"머리 조심하세요\" -> \"데멩이 맹심헙써\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ4PFBTpSr0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD_XvYHxfVn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "35703962-ae9d-45c8-8bc0-8b4a0895f94d"
      },
      "source": [
        "  # 손실 그래프\n",
        "  plt.plot(history.history['loss'], 'y', label='train loss')\n",
        "  plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # 정확도 그래프\n",
        "  plt.plot(history.history['acc'], 'y', label='train acc')\n",
        "  plt.plot(history.history['val_acc'], 'r', label='val acc')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxoQJS+jGGBMmLKEbY0yY+P/qiUf3/xxmLwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrKRwrR3Tppv",
        "colab_type": "text"
      },
      "source": [
        "테스트셋 만들기."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yegVgDMzfbdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOCte51Zf5Yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "dd118f9b-ebec-45ff-fb7c-e670d9aecd0c"
      },
      "source": [
        "input_texts\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeff버래기',\n",
              " '바당에 괴기 사레 마씀',\n",
              " '무사 누게 왔수과',\n",
              " '서울서 족은 아방네 완 마씀',\n",
              " '게민 멩심허영 갔당 옵서',\n",
              " '고랑은 몰라 마씀',\n",
              " '제주도에 왕 봐사 알아짐니다',\n",
              " '돌도 많고 보롬도 많고 비바리도 많고',\n",
              " '유채꽃도 곱드락 호게 피었수다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmKB6pkSsn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "d8474768-f6d4-4461-d617-41a26aa2a663"
      },
      "source": [
        "# 테스트 데이터 셋 만들기\n",
        "\n",
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 9\n",
            "Number of unique input tokens: 62\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3OWr5U-e1dV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e75b7990-01c6-405e-d778-c798b2c546b0"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력 문장을 인코딩\n",
        "  enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "  # 디코더의 입력으로 쓸 단일 문자\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "  # 문장 생성\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "    # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "    dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "        [target_seq, states_value, enc_outputs])\n",
        " \n",
        "    # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        " \n",
        "    # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        " \n",
        "    # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    states_value = h\n",
        " \n",
        "  return decoded_sentence\n",
        "\n",
        "for seq_index in range(9):\n",
        "  input_seq = encoder_input_data_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-07cfbd166981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"{}\" -> \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-07cfbd166981>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# 입력 문장을 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 디코더의 입력으로 쓸 단일 문자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (165, 787) but got array with shape (20, 62)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRr-uZL4e1hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-PbxIwe1kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCh33atHwvI2",
        "colab_type": "code",
        "outputId": "5591393b-adab-4a2a-e69c-1f7553a29e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_model.predict(encoder_input_data[1:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.0000000e+00, -0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.6329135e-01,\n",
              "          6.4644217e-04, -0.0000000e+00, -9.2373818e-02,  2.9097532e-28,\n",
              "         -0.0000000e+00, -8.5620570e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -9.6190804e-01,  0.0000000e+00,  1.4762883e-31,  0.0000000e+00,\n",
              "         -2.5769413e-02, -1.5891892e-01,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -4.8811927e-01, -5.2259541e-01,\n",
              "          2.4740072e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -4.8581851e-03, -1.8517128e-01, -0.0000000e+00, -4.0916356e-01,\n",
              "          0.0000000e+00, -9.0105736e-01, -0.0000000e+00,  5.5774748e-03,\n",
              "         -2.9330635e-01, -9.8345417e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,  3.7912405e-01,\n",
              "         -8.5560732e-02, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -2.9002559e-01, -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  7.6037529e-03,  0.0000000e+00, -0.0000000e+00,\n",
              "          9.0489155e-01,  2.0254247e-01,  0.0000000e+00,  4.6030561e-23,\n",
              "          0.0000000e+00,  0.0000000e+00, -7.6174669e-02, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -0.0000000e+00,  2.5714195e-01,\n",
              "          8.8205129e-02, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00, -4.2958260e-02, -4.8764575e-01,\n",
              "         -0.0000000e+00,  0.0000000e+00,  4.7477731e-01,  8.6879867e-01,\n",
              "          1.1599462e-02,  0.0000000e+00,  9.0954005e-04, -1.2454973e-01,\n",
              "          0.0000000e+00,  0.0000000e+00,  9.9968106e-01, -9.1520578e-02,\n",
              "          7.9044974e-01, -2.3096931e-01,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  4.7353655e-01,  4.7984362e-02, -6.8209851e-01,\n",
              "          0.0000000e+00, -7.3482305e-01, -8.5555112e-31, -5.8489289e-02,\n",
              "          0.0000000e+00,  1.3068425e-05, -0.0000000e+00, -5.5376284e-02,\n",
              "         -0.0000000e+00,  0.0000000e+00, -0.0000000e+00, -9.4534010e-02,\n",
              "         -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -9.4223726e-01, -4.8242757e-01, -0.0000000e+00,\n",
              "          1.2427284e-01,  0.0000000e+00,  6.2701292e-02, -9.9980128e-01,\n",
              "         -1.8277472e-01, -5.0021201e-02,  0.0000000e+00,  6.6289696e-04,\n",
              "          0.0000000e+00, -3.8783801e-01, -0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00, -1.9770602e-02,  0.0000000e+00, -9.9869603e-01,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -2.7131078e-01,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.6902500e-01,\n",
              "          0.0000000e+00, -1.5806250e-02,  0.0000000e+00,  0.0000000e+00,\n",
              "          5.6324024e-37,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          2.4540097e-02,  7.3298591e-01, -1.1825219e-01, -0.0000000e+00,\n",
              "         -4.2891189e-01, -1.8483192e-02, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -0.0000000e+00, -7.6095667e-04,  0.0000000e+00,\n",
              "          3.3993727e-01, -1.1197328e-01, -3.5808769e-01, -0.0000000e+00,\n",
              "         -0.0000000e+00,  5.7189941e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "          1.0680524e-01, -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -6.4338589e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -9.7646445e-01,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -4.5837779e-03,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -7.2626758e-01,  1.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00,  1.8077916e-01, -0.0000000e+00,\n",
              "         -0.0000000e+00,  3.1599915e-01, -7.0703638e-01,  0.0000000e+00,\n",
              "          0.0000000e+00, -3.6475569e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  2.0247820e-01,  9.1961674e-02, -1.0000000e+00,\n",
              "         -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -4.7337539e-03,\n",
              "         -0.0000000e+00, -0.0000000e+00,  3.1825322e-01,  0.0000000e+00,\n",
              "          3.3561704e-03,  0.0000000e+00,  9.5703237e-02, -9.9436027e-01,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -6.5144464e-05,\n",
              "         -0.0000000e+00,  1.5679682e-02,  0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00,  4.9511697e-02,  8.6975589e-02,  2.4072388e-01,\n",
              "          1.7965989e-30,  0.0000000e+00, -0.0000000e+00,  2.3980862e-02,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -5.6163829e-02, -9.9846846e-01]],\n",
              "       dtype=float32),\n",
              " array([[ 0.00000000e+00, -0.00000000e+00, -2.98531342e+01,\n",
              "          0.00000000e+00,  0.00000000e+00,  5.01047707e+01,\n",
              "          1.34669174e+02,  2.75115460e-01,  7.64443817e+01,\n",
              "         -1.37504721e+00, -4.31306332e-01,  5.30959675e-28,\n",
              "         -9.65302825e-01, -1.76891494e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.97083485e+00,  0.00000000e+00,\n",
              "          3.09288409e-31,  3.63989830e+00, -1.22796074e+02,\n",
              "         -1.06463289e+01,  0.00000000e+00, -0.00000000e+00,\n",
              "          0.00000000e+00,  1.52326233e+02, -6.13411427e-01,\n",
              "         -1.31800199e+00,  5.11115372e-01,  3.95650327e-01,\n",
              "          4.47818041e+00,  0.00000000e+00, -2.82499511e-02,\n",
              "         -1.50106781e+02, -9.98390656e+01, -9.97066736e-01,\n",
              "          0.00000000e+00, -1.47781253e+00, -1.52559143e+02,\n",
              "          5.97162971e+01, -1.15213966e+00, -6.47213936e+00,\n",
              "          3.40338945e+00,  5.45292816e+01, -1.35125923e+00,\n",
              "          0.00000000e+00, -9.55139637e+00,  5.35434306e-01,\n",
              "         -4.20049953e+00, -0.00000000e+00,  8.07391281e+01,\n",
              "         -0.00000000e+00, -1.34347717e+02, -2.83787346e+00,\n",
              "          8.53425522e+01,  1.00287371e+01, -0.00000000e+00,\n",
              "          3.89394760e-02,  7.21604767e+01, -2.84739571e+01,\n",
              "          1.49858141e+00,  8.66559505e-01,  0.00000000e+00,\n",
              "          5.27181764e-23,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.94841194e+00, -2.42356211e-01,  7.82024956e+00,\n",
              "          0.00000000e+00, -2.48831773e+00,  2.10909100e+01,\n",
              "          1.51339096e+02, -7.86861944e+00,  0.00000000e+00,\n",
              "         -1.09752560e+00, -8.30106125e+01,  1.05638433e+00,\n",
              "         -1.44126923e+02, -1.39781160e+01, -0.00000000e+00,\n",
              "          0.00000000e+00,  9.87113647e+01,  4.58214712e+00,\n",
              "          3.48192382e+00,  0.00000000e+00,  9.85414684e-02,\n",
              "         -5.12531340e-01,  1.79604130e+01,  1.56015730e+01,\n",
              "          4.37174606e+00, -3.79684687e-01,  1.07262921e+00,\n",
              "         -7.01352775e-01,  0.00000000e+00, -7.02870488e-01,\n",
              "          4.47108955e+01,  1.00930511e+02,  0.00000000e+00,\n",
              "         -6.31350219e-01,  1.52941370e+00,  1.47939575e+02,\n",
              "          9.42515259e+01, -7.03328323e+00,  1.59019928e+01,\n",
              "         -1.40816402e+00, -1.14104644e-30, -4.34135765e-01,\n",
              "          5.03126860e-01,  3.51720482e-05, -6.04815602e-01,\n",
              "         -2.18326032e-01, -1.26794418e+02,  1.80413389e+00,\n",
              "         -1.26950867e+02, -2.67322235e+01, -1.13064095e-01,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.75762594e+00, -7.57123709e-01,\n",
              "         -0.00000000e+00,  5.61144233e-01,  4.04905224e+00,\n",
              "          5.16400814e-01, -4.60827446e+00, -4.16803002e-01,\n",
              "         -1.49123383e+02,  3.38845491e+00,  3.63321020e-03,\n",
              "          0.00000000e+00, -7.07973862e+01, -1.48403478e+00,\n",
              "         -4.20976996e-01, -9.46586132e-01, -5.55929899e+00,\n",
              "          0.00000000e+00, -3.66741586e+00, -1.50491745e+02,\n",
              "         -1.30656372e+02,  1.25606880e+02, -6.02356613e-01,\n",
              "          8.84825349e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "          5.57098269e-01,  2.85795659e-01, -7.32855141e-01,\n",
              "          1.58492327e+00,  0.00000000e+00,  1.47897632e-36,\n",
              "          0.00000000e+00, -8.95267391e+00,  4.56423424e-02,\n",
              "         -6.76231384e-01,  1.21814432e+01,  0.00000000e+00,\n",
              "          6.62447023e+00, -6.24138975e+00, -1.23128414e+00,\n",
              "          1.51434036e+02, -1.85090661e-01,  1.33262224e+01,\n",
              "          9.35149908e-01, -8.43520508e+01, -0.00000000e+00,\n",
              "         -1.87059665e+00, -1.36203461e+02, -1.15526062e+02,\n",
              "          0.00000000e+00,  0.00000000e+00, -5.28743744e+00,\n",
              "         -4.28142399e-03,  0.00000000e+00,  5.57438431e+01,\n",
              "         -1.12444803e-01, -7.98213363e-01, -3.45038652e-01,\n",
              "         -9.80087146e-02,  1.07140183e+00,  0.00000000e+00,\n",
              "          1.19289026e+01,  8.01095104e+00, -1.92479014e+00,\n",
              "          2.59952545e+00,  1.58299446e+00,  0.00000000e+00,\n",
              "         -2.12397432e+00,  0.00000000e+00,  5.42274475e-01,\n",
              "         -2.21527672e+00,  0.00000000e+00,  1.75964146e+01,\n",
              "         -2.75903702e+00, -1.19178796e+00,  0.00000000e+00,\n",
              "         -3.62383866e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         -7.28727102e+00,  1.40233490e+02,  1.38978500e+02,\n",
              "         -1.32205475e+02,  0.00000000e+00,  1.07438957e+02,\n",
              "         -1.68638859e+01, -1.54776020e+01,  5.51546693e-01,\n",
              "         -3.50762100e+01,  3.59794855e+00,  0.00000000e+00,\n",
              "         -1.29502472e+02,  0.00000000e+00,  1.01906616e+02,\n",
              "         -1.14045391e+01,  3.80389661e-01,  5.82386672e-01,\n",
              "         -2.35989819e+01, -0.00000000e+00, -0.00000000e+00,\n",
              "         -6.28876114e+00, -1.21654216e-02, -0.00000000e+00,\n",
              "         -1.35992233e+02,  5.54244578e-01,  0.00000000e+00,\n",
              "          6.99225161e-03,  5.47310486e+01,  1.03944087e+00,\n",
              "         -2.93411875e+00, -7.10304642e+00, -0.00000000e+00,\n",
              "          0.00000000e+00, -1.34732662e-04, -1.46412430e+01,\n",
              "          2.07393646e+00,  0.00000000e+00, -5.52425041e+01,\n",
              "         -4.39005566e+00,  1.45118043e-01,  2.00735474e+00,\n",
              "          1.41495163e+02,  2.80820861e-30,  1.17513478e-01,\n",
              "         -2.34038830e-01,  3.31161946e-01, -7.67882442e+00,\n",
              "         -9.32745590e+01,  2.23502254e+01, -1.27744579e+01,\n",
              "          0.00000000e+00,  2.05016117e+01, -7.43866488e-02,\n",
              "         -3.58693957e+00]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ3WbpinoRgH",
        "colab_type": "code",
        "outputId": "e057efd1-d414-45b8-c3ae-35fd3f9822a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.history.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.90837691092862,\n",
              "  0.9354104222362614,\n",
              "  0.9352390464916024,\n",
              "  0.9354153230626095,\n",
              "  0.9354104250135388,\n",
              "  0.9354104203135309,\n",
              "  0.9354104260817223,\n",
              "  0.9354985636194975,\n",
              "  0.9354740763650573,\n",
              "  0.9357874575054347,\n",
              "  0.9370115768952182,\n",
              "  0.9379859761097953,\n",
              "  0.9379174260682958,\n",
              "  0.9392345844631127,\n",
              "  0.9392052049277931,\n",
              "  0.9407378007861449,\n",
              "  0.9414135181348383,\n",
              "  0.9425886760475815,\n",
              "  0.94316646681037,\n",
              "  0.9442583754071198,\n",
              "  0.9448704377724706,\n",
              "  0.945830150530757,\n",
              "  0.9463393848429444,\n",
              "  0.9472452385023931,\n",
              "  0.9479160537429181,\n",
              "  0.9490373484977257,\n",
              "  0.9495367941890566,\n",
              "  0.9505209937745098,\n",
              "  0.9513484948852157,\n",
              "  0.9521123431489459,\n",
              "  0.952788058574909,\n",
              "  0.9535029479252395,\n",
              "  0.9545067294524134,\n",
              "  0.9551873378001661,\n",
              "  0.9555986517219133,\n",
              "  0.9564947028741188,\n",
              "  0.9572438636133748,\n",
              "  0.9581693034872787,\n",
              "  0.9589380525773571,\n",
              "  0.9600250680386806,\n",
              "  0.9607056838637185,\n",
              "  0.9617731156742274,\n",
              "  0.9628699238155051,\n",
              "  0.9635407493105926,\n",
              "  0.9643927425893831,\n",
              "  0.9656119639300959,\n",
              "  0.9662093338573278,\n",
              "  0.9673306288257721,\n",
              "  0.9682854411849838,\n",
              "  0.9693332959674166,\n",
              "  0.9702979027156762,\n",
              "  0.9709491358008436,\n",
              "  0.9718402938176227,\n",
              "  0.9728587699192827,\n",
              "  0.9735638546260027,\n",
              "  0.9750034322020829,\n",
              "  0.9753266011087698,\n",
              "  0.9763058887587653,\n",
              "  0.9772019497382598,\n",
              "  0.9780343557344116,\n",
              "  0.9786317256616435,\n",
              "  0.9775593919566028,\n",
              "  0.9804727996976572,\n",
              "  0.9809379712227853,\n",
              "  0.9807323230210171,\n",
              "  0.9815059616146976,\n",
              "  0.9820298909286445,\n",
              "  0.9826272614967866,\n",
              "  0.983200155919598,\n",
              "  0.9838073153222333,\n",
              "  0.9843067580226502,\n",
              "  0.9844830275436456,\n",
              "  0.9850706022272828,\n",
              "  0.9854574263309492,\n",
              "  0.9859127979124745,\n",
              "  0.9859519750413929,\n",
              "  0.9863485916113768,\n",
              "  0.9866374837882202,\n",
              "  0.9869459647431595,\n",
              "  0.9870928637015777,\n",
              "  0.9873034133706041,\n",
              "  0.9874649953671254,\n",
              "  0.9877979580219501,\n",
              "  0.9881309202495014,\n",
              "  0.9882043713309859,\n",
              "  0.9882729111179229,\n",
              "  0.9884149111727233,\n",
              "  0.988522636847684,\n",
              "  0.9881896669292108,\n",
              "  0.9888262088580798,\n",
              "  0.9888360090153192,\n",
              "  0.9890808236641696,\n",
              "  0.9890808277232672,\n",
              "  0.9892375140207216,\n",
              "  0.9892571047215479,\n",
              "  0.9891395863666329,\n",
              "  0.9892522053906567,\n",
              "  0.9893550225483474,\n",
              "  0.9895606775864906,\n",
              "  0.9896292286961736],\n",
              " 'loss': [1.0096772083458507,\n",
              "  0.4459582566146782,\n",
              "  0.5313804481832785,\n",
              "  0.45794955141655436,\n",
              "  0.4284211137602406,\n",
              "  0.43195175376844236,\n",
              "  0.4269149436959229,\n",
              "  0.4198300125991999,\n",
              "  0.40419935496477244,\n",
              "  0.38667374582273556,\n",
              "  0.40547882933770457,\n",
              "  0.35477240901694074,\n",
              "  0.38163947621126754,\n",
              "  0.34341190418889445,\n",
              "  0.3816452809345765,\n",
              "  0.32727003749126177,\n",
              "  0.34477989936387665,\n",
              "  0.31009486867749136,\n",
              "  0.3107977184770782,\n",
              "  0.296052504397635,\n",
              "  0.353442058875142,\n",
              "  0.2829253629757939,\n",
              "  0.2789535340869726,\n",
              "  0.2722864289864844,\n",
              "  0.26841296271611287,\n",
              "  0.25975411120922337,\n",
              "  0.2558082861285056,\n",
              "  0.2514205320761623,\n",
              "  0.2440831141018953,\n",
              "  0.23859162762173616,\n",
              "  0.23346964635729361,\n",
              "  0.23040057777503914,\n",
              "  0.22234650623841098,\n",
              "  0.21799792605702595,\n",
              "  0.21396246621899281,\n",
              "  0.2089877690465647,\n",
              "  0.20390964910975493,\n",
              "  0.19830190708133055,\n",
              "  0.19320864094200954,\n",
              "  0.18858892174177272,\n",
              "  0.18335340911769524,\n",
              "  0.17914873393633032,\n",
              "  0.17309058684602005,\n",
              "  0.1693868309686688,\n",
              "  0.16545846102271883,\n",
              "  0.15966681254807338,\n",
              "  0.15639500052911834,\n",
              "  0.15184295978597415,\n",
              "  0.14713666884488957,\n",
              "  0.14274392450582168,\n",
              "  0.13894881623192928,\n",
              "  0.13497098740924643,\n",
              "  0.13157488849000692,\n",
              "  0.12706793801972516,\n",
              "  0.12411574992654999,\n",
              "  0.12010558029656769,\n",
              "  0.11675590840184988,\n",
              "  0.11371284181178684,\n",
              "  0.11013143573717404,\n",
              "  0.1075243863901357,\n",
              "  0.10419286979782966,\n",
              "  0.10961638249483587,\n",
              "  0.09778666661845313,\n",
              "  0.09583109470358031,\n",
              "  0.09459021919837562,\n",
              "  0.09179557988079645,\n",
              "  0.08991102660642303,\n",
              "  0.08756189670507199,\n",
              "  0.08541964699504195,\n",
              "  0.0829613200759375,\n",
              "  0.08074136524324349,\n",
              "  0.07920727577047108,\n",
              "  0.07697737513370412,\n",
              "  0.0753729007470565,\n",
              "  0.07351873160797208,\n",
              "  0.07251052630524482,\n",
              "  0.07038084967696111,\n",
              "  0.06892894291215473,\n",
              "  0.06748521960871194,\n",
              "  0.06643989495265441,\n",
              "  0.06475451943801723,\n",
              "  0.06376133218247404,\n",
              "  0.06274024730942156,\n",
              "  0.06147409663085015,\n",
              "  0.060475144401780166,\n",
              "  0.0594091140214474,\n",
              "  0.05859340213265898,\n",
              "  0.05770886611981204,\n",
              "  0.05873666495405218,\n",
              "  0.05549039102850422,\n",
              "  0.05519866908643408,\n",
              "  0.05436327612848692,\n",
              "  0.05406563385893794,\n",
              "  0.05292724322621113,\n",
              "  0.05244507819520957,\n",
              "  0.05285052322251822,\n",
              "  0.05200746125378062,\n",
              "  0.051306821218955474,\n",
              "  0.0502657447023631,\n",
              "  0.04984785213158549]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHKk1sM1GiVg",
        "colab_type": "code",
        "outputId": "35d39507-bb81-48c9-c21a-d654ac863903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "for seq_index in range(2):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 5]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: 하르방 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 할망 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLt1JGEtHGQK",
        "colab_type": "code",
        "outputId": "f13c1c8a-ce68-4f6a-d43f-5a4e9e25c703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoded_sentence[1:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'감물'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkuN6RnpGPHz",
        "colab_type": "code",
        "outputId": "dd320e72-d6f3-4351-e0da-33e89b69818b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 10]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: 하르방 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 할망 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 아방 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 어멍 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 비바리 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 괸당 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 걸바시 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 넹바리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 다슴아돌 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 말젯놈 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 소나이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 성님 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 작산 거 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 좀녀 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 촐람생이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 홀아방 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 가달 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 꼴랑지 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 구뚱배기 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 꽝 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 굴레 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 대망생이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 등땡이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 또꼬망 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 모감지 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 베 봉탱이 \n",
            "Decoded sentence:  어 지\n",
            "\n",
            "-\n",
            "Input sentence: 베아지 볼라불라\n",
            "Decoded sentence:  어 지\n",
            "\n",
            "-\n",
            "Input sentence: 상판이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 야게기 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 야굴탁 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 임댕이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 정겡이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 저껭이 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 조금태기 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 좀짐팽이 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 허운데기 \n",
            "Decoded sentence:  잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 허벅다리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 놋 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 간수메 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 개역 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 것 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 괴기 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 바당괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 돗괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 쇠괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 도괴기 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 곤떡 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 곤밥 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 놈삐 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 대사니김치 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 마농 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 마농 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 조배기 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 촐래 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 촘지금 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 짐치 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 촙쏠 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 조팝 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 갈옷 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 갈 적삼 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 갈 중이 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 강알터진 바지 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 게와 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 단취 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 밀랑 페랭이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 보선 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 소중이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 신착 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 찍신 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 좀뱅이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 등지게 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 고장중이 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 도폭 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 두루막 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 베불레기 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 우장 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 저구리 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 지성귀 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 지서귀 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 쪼께 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 치메 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 건대 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 사모관대 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 시미옷 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 제복 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 망근 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 방립 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 벙것 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 상갓 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 탕근 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 풍뎅이 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 휘양 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 낭저 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 달리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 빈네 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 상퉁이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 얼레기 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 얼레빗 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 쪽도리 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 쳉빗 \n",
            "Decoded sentence:  돼지\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}