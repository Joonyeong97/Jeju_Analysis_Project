{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kor_jeju.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEIky_zshPjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://neurowhai.tistory.com/292"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa4IReo6Cc7a",
        "colab_type": "code",
        "outputId": "686f61e0-9abf-499a-c8d6-73dd43f1dbed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "device_lib.list_local_devices()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 3876883829019089860, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 5933003659533636849\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 12620358854082576940\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 15956161332\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 11978132078730237417\n",
              " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNlo6VGXFllH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xGdGylMFawA",
        "colab_type": "code",
        "outputId": "7c37d48a-f630-4e38-bd40-d09e8140a3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Q2fuUMCOaO",
        "colab_type": "code",
        "outputId": "eb614655-3c57-4c02-ac6a-9e895e204aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional, Dropout, Embedding\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import matplotlib\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 120  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = '/content/dataset.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def RepeatVectorLayer(rep, axis):\n",
        "  return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis),\n",
        "                      lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n",
        "\n",
        "\n",
        "# 인코더 생성\n",
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "# dropout 전\n",
        "# encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "\n",
        "encoder = layers.GRU(latent_dim,dropout=0.25,recurrent_dropout=0.25, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "\n",
        "# 디코더 생성\n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n",
        "# dropout 전\n",
        "# decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder = layers.GRU(latent_dim,dropout=0.25,recurrent_dropout=0.25, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
        "\n",
        "# embedding test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# attention 생성\n",
        "'''\n",
        "어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, \n",
        "인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. \n",
        "단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, \n",
        "해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 \n",
        "집중(attention)해서 보게 됩니다.\n",
        "'''\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "# 입력을 n 번 반복합니다.\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "# 입력을 n 번 반복합니다.\n",
        "repeat_e = repeat_e_layer(encoder_outputs)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "#layers.Concatenate는 입력 목록을 연결하는 계층입니다.\n",
        "# 연결 축을 제외하고 모두 동일한 모양의 텐서 목록을 입력으로 사용하고 \n",
        "# 모든 입력의 연결 인 단일 텐서를 반환합니다.\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh')\n",
        "# Dense 클래스 객체를 TimeDistributed wrapper를 사용하여 3차원 텐서 입력을 받을 수 있게 확장\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "\n",
        "dense2_t_score_layer = layers.Dense(1)\n",
        "# Dense 클래스 객체를 TimeDistributed wrapper를 사용하여 3차원 텐서 입력을 받을 수 있게 확장\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "# soft max 설정\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "# 입력을 n 번 반복합니다 RepeatVectorLayer\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "# layers.Permute 주어진 패턴에 따라 입력 치수를 변경합니다.\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs)\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply() # 행렬곱\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "'''입력 목록을 연결하는 계층입니다.\n",
        "연결 축을 제외하고 모두 동일한 모양의 텐서 목록을 입력으로 \n",
        "사용하고 모든 입력의 연결 인 단일 텐서를 반환합니다.'''\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh')\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(attention_output)\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "model = models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "che = 'atten_GRU_weight_g.h5'\n",
        "point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1,callbacks=[point,early_stopping])\n",
        "# Save model\n",
        "model.save('atten_GRU_weight.h5')\n",
        "# \n",
        "\n",
        "\n",
        "# Next: inference mode (sampling).\n",
        "# Here's the drill:\n",
        "# 1) 입력을 인코딩하고 초기 디코더 상태 검색\n",
        "# 2) 이 초기 상태로 디코더 한 단계 실행\n",
        "# \"시퀀스 시작\" 토큰을 대상으로 한다.\n",
        "# 출력이 다음 대상 토큰임\n",
        "# 3) 현재 대상 토큰 및 현재 상태로 반복\n",
        "\n",
        "# 샘플링 모델 정의\n",
        "encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h])\n",
        "encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim))\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(1, num_decoder_tokens))\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h)\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs_input)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_att_outputs = decoder_dense(attention_output)\n",
        "\n",
        "decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input],\n",
        "                            [decoder_outputs, decoder_h, decoder_att_outputs])\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "  # 입력 문장을 인코딩\n",
        "  enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "  # 디코더의 입력으로 쓸 단일 문자\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "  # 문장 생성\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "    # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "    dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "        [target_seq, states_value, enc_outputs])\n",
        " \n",
        "    # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        " \n",
        "    # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        " \n",
        "    # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    states_value = h\n",
        " \n",
        "  return decoded_sentence\n",
        "\n",
        "for seq_index in range(30):\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1175\n",
            "Number of unique input tokens: 780\n",
            "Number of unique output tokens: 719\n",
            "Max sequence length for inputs: 165\n",
            "Max sequence length for outputs: 183\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 165, 780)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 183, 719)     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     [(None, 165, 256), ( 796416      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     [(None, 183, 256), ( 749568      input_2[0][0]                    \n",
            "                                                                 gru_1[0][1]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 183, 165, 256 0           gru_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 183, 165, 256 0           gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 183, 165, 512 0           lambda_1[0][0]                   \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 183, 165, 128 65664       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 183, 165, 1)  129         time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 183, 165)     0           time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "softmax_1 (Softmax)             (None, 183, 165)     0           reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 256, 165)     0           gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 183, 256, 165 0           softmax_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 183, 256, 165 0           permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 183, 256, 165 0           lambda_3[0][0]                   \n",
            "                                                                 lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 183, 256)     0           multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 183, 512)     0           lambda_5[0][0]                   \n",
            "                                                                 gru_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 183, 256)     131328      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 183, 719)     184783      time_distributed_3[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,927,888\n",
            "Trainable params: 1,927,888\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 940 samples, validate on 235 samples\n",
            "Epoch 1/120\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "940/940 [==============================] - 33s 36ms/step - loss: 0.3417 - acc: 0.0135 - val_loss: 0.5597 - val_acc: 0.0279\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.55970, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 2/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.3026 - acc: 0.0142 - val_loss: 0.5442 - val_acc: 0.0277\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.55970 to 0.54418, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 3/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2903 - acc: 0.0150 - val_loss: 0.5384 - val_acc: 0.0261\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.54418 to 0.53844, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 4/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2804 - acc: 0.0157 - val_loss: 0.4960 - val_acc: 0.0297\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.53844 to 0.49598, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 5/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2721 - acc: 0.0171 - val_loss: 0.4782 - val_acc: 0.0345\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.49598 to 0.47823, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 6/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2665 - acc: 0.0177 - val_loss: 0.4686 - val_acc: 0.0344\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.47823 to 0.46860, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 7/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2599 - acc: 0.0182 - val_loss: 0.4665 - val_acc: 0.0380\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.46860 to 0.46648, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 8/120\n",
            "940/940 [==============================] - 31s 32ms/step - loss: 0.2550 - acc: 0.0193 - val_loss: 0.4544 - val_acc: 0.0385\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.46648 to 0.45438, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 9/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2506 - acc: 0.0199 - val_loss: 0.4421 - val_acc: 0.0394\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.45438 to 0.44213, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 10/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2444 - acc: 0.0205 - val_loss: 0.4406 - val_acc: 0.0399\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.44213 to 0.44057, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 11/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2393 - acc: 0.0213 - val_loss: 0.4281 - val_acc: 0.0415\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.44057 to 0.42810, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 12/120\n",
            "940/940 [==============================] - 31s 32ms/step - loss: 0.2343 - acc: 0.0223 - val_loss: 0.4259 - val_acc: 0.0424\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.42810 to 0.42589, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 13/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.2299 - acc: 0.0224 - val_loss: 0.4183 - val_acc: 0.0433\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.42589 to 0.41834, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 14/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2247 - acc: 0.0231 - val_loss: 0.4111 - val_acc: 0.0449\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.41834 to 0.41110, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 15/120\n",
            "940/940 [==============================] - 31s 32ms/step - loss: 0.2210 - acc: 0.0239 - val_loss: 0.4068 - val_acc: 0.0464\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.41110 to 0.40679, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 16/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2164 - acc: 0.0242 - val_loss: 0.4155 - val_acc: 0.0428\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.40679\n",
            "Epoch 17/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2130 - acc: 0.0247 - val_loss: 0.4083 - val_acc: 0.0461\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.40679\n",
            "Epoch 18/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2098 - acc: 0.0252 - val_loss: 0.4104 - val_acc: 0.0444\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.40679\n",
            "Epoch 19/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2059 - acc: 0.0255 - val_loss: 0.4014 - val_acc: 0.0475\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.40679 to 0.40137, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 20/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.2013 - acc: 0.0262 - val_loss: 0.4029 - val_acc: 0.0461\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.40137\n",
            "Epoch 21/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1980 - acc: 0.0267 - val_loss: 0.4057 - val_acc: 0.0452\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.40137\n",
            "Epoch 22/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1957 - acc: 0.0268 - val_loss: 0.4011 - val_acc: 0.0471\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.40137 to 0.40114, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 23/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1926 - acc: 0.0271 - val_loss: 0.3945 - val_acc: 0.0485\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.40114 to 0.39453, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 24/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1874 - acc: 0.0279 - val_loss: 0.3943 - val_acc: 0.0483\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.39453 to 0.39426, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 25/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1845 - acc: 0.0285 - val_loss: 0.3941 - val_acc: 0.0484\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.39426 to 0.39411, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 26/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1825 - acc: 0.0288 - val_loss: 0.4005 - val_acc: 0.0471\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.39411\n",
            "Epoch 27/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1792 - acc: 0.0288 - val_loss: 0.3938 - val_acc: 0.0485\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.39411 to 0.39381, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 28/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1762 - acc: 0.0295 - val_loss: 0.3920 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.39381 to 0.39200, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 29/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1729 - acc: 0.0298 - val_loss: 0.3879 - val_acc: 0.0496\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.39200 to 0.38788, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 30/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1709 - acc: 0.0301 - val_loss: 0.3905 - val_acc: 0.0483\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.38788\n",
            "Epoch 31/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1676 - acc: 0.0307 - val_loss: 0.3849 - val_acc: 0.0500\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.38788 to 0.38495, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 32/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1661 - acc: 0.0309 - val_loss: 0.3872 - val_acc: 0.0504\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.38495\n",
            "Epoch 33/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1630 - acc: 0.0313 - val_loss: 0.3930 - val_acc: 0.0483\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.38495\n",
            "Epoch 34/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1599 - acc: 0.0318 - val_loss: 0.3906 - val_acc: 0.0490\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.38495\n",
            "Epoch 35/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1577 - acc: 0.0321 - val_loss: 0.3928 - val_acc: 0.0489\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.38495\n",
            "Epoch 36/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1553 - acc: 0.0325 - val_loss: 0.3916 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.38495\n",
            "Epoch 37/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1518 - acc: 0.0332 - val_loss: 0.3879 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.38495\n",
            "Epoch 38/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1494 - acc: 0.0336 - val_loss: 0.3877 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.38495\n",
            "Epoch 39/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1467 - acc: 0.0336 - val_loss: 0.3984 - val_acc: 0.0483\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.38495\n",
            "Epoch 40/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1455 - acc: 0.0339 - val_loss: 0.3842 - val_acc: 0.0507\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.38495 to 0.38416, saving model to atten_GRU_weight_g.h5\n",
            "Epoch 41/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1427 - acc: 0.0346 - val_loss: 0.3848 - val_acc: 0.0499\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.38416\n",
            "Epoch 42/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1412 - acc: 0.0349 - val_loss: 0.3986 - val_acc: 0.0492\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.38416\n",
            "Epoch 43/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1367 - acc: 0.0357 - val_loss: 0.3931 - val_acc: 0.0503\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.38416\n",
            "Epoch 44/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1370 - acc: 0.0352 - val_loss: 0.3966 - val_acc: 0.0492\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.38416\n",
            "Epoch 45/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1348 - acc: 0.0361 - val_loss: 0.3936 - val_acc: 0.0508\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.38416\n",
            "Epoch 46/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1322 - acc: 0.0362 - val_loss: 0.3882 - val_acc: 0.0506\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.38416\n",
            "Epoch 47/120\n",
            "940/940 [==============================] - 30s 32ms/step - loss: 0.1298 - acc: 0.0368 - val_loss: 0.3855 - val_acc: 0.0514\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.38416\n",
            "Epoch 48/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1273 - acc: 0.0372 - val_loss: 0.3871 - val_acc: 0.0516\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.38416\n",
            "Epoch 49/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1250 - acc: 0.0374 - val_loss: 0.3938 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.38416\n",
            "Epoch 50/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1223 - acc: 0.0381 - val_loss: 0.3924 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.38416\n",
            "Epoch 51/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1203 - acc: 0.0381 - val_loss: 0.3924 - val_acc: 0.0509\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.38416\n",
            "Epoch 52/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1179 - acc: 0.0389 - val_loss: 0.3980 - val_acc: 0.0497\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.38416\n",
            "Epoch 53/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1148 - acc: 0.0394 - val_loss: 0.3958 - val_acc: 0.0512\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.38416\n",
            "Epoch 54/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1148 - acc: 0.0394 - val_loss: 0.3918 - val_acc: 0.0520\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.38416\n",
            "Epoch 55/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1125 - acc: 0.0401 - val_loss: 0.3886 - val_acc: 0.0520\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.38416\n",
            "Epoch 56/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1110 - acc: 0.0401 - val_loss: 0.3921 - val_acc: 0.0519\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.38416\n",
            "Epoch 57/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1098 - acc: 0.0404 - val_loss: 0.3912 - val_acc: 0.0524\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.38416\n",
            "Epoch 58/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1068 - acc: 0.0409 - val_loss: 0.3971 - val_acc: 0.0514\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.38416\n",
            "Epoch 59/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.1058 - acc: 0.0414 - val_loss: 0.3939 - val_acc: 0.0520\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.38416\n",
            "Epoch 60/120\n",
            "940/940 [==============================] - 31s 34ms/step - loss: 0.1047 - acc: 0.0413 - val_loss: 0.3981 - val_acc: 0.0520\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.38416\n",
            "Epoch 61/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1022 - acc: 0.0418 - val_loss: 0.3995 - val_acc: 0.0510\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.38416\n",
            "Epoch 62/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.1002 - acc: 0.0422 - val_loss: 0.3998 - val_acc: 0.0511\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.38416\n",
            "Epoch 63/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0978 - acc: 0.0430 - val_loss: 0.3910 - val_acc: 0.0526\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.38416\n",
            "Epoch 64/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0970 - acc: 0.0431 - val_loss: 0.3951 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.38416\n",
            "Epoch 65/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0943 - acc: 0.0435 - val_loss: 0.3941 - val_acc: 0.0524\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.38416\n",
            "Epoch 66/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0948 - acc: 0.0434 - val_loss: 0.4005 - val_acc: 0.0522\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.38416\n",
            "Epoch 67/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0916 - acc: 0.0439 - val_loss: 0.4005 - val_acc: 0.0523\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.38416\n",
            "Epoch 68/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0898 - acc: 0.0443 - val_loss: 0.3987 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.38416\n",
            "Epoch 69/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0869 - acc: 0.0450 - val_loss: 0.4042 - val_acc: 0.0519\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.38416\n",
            "Epoch 70/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0867 - acc: 0.0451 - val_loss: 0.3970 - val_acc: 0.0531\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.38416\n",
            "Epoch 71/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0864 - acc: 0.0454 - val_loss: 0.3997 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.38416\n",
            "Epoch 72/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0844 - acc: 0.0458 - val_loss: 0.3977 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.38416\n",
            "Epoch 73/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0809 - acc: 0.0465 - val_loss: 0.4030 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.38416\n",
            "Epoch 74/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0804 - acc: 0.0465 - val_loss: 0.4052 - val_acc: 0.0526\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.38416\n",
            "Epoch 75/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0795 - acc: 0.0463 - val_loss: 0.3996 - val_acc: 0.0532\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.38416\n",
            "Epoch 76/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0774 - acc: 0.0475 - val_loss: 0.4043 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.38416\n",
            "Epoch 77/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0768 - acc: 0.0472 - val_loss: 0.4086 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.38416\n",
            "Epoch 78/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0753 - acc: 0.0476 - val_loss: 0.4046 - val_acc: 0.0527\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.38416\n",
            "Epoch 79/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0742 - acc: 0.0481 - val_loss: 0.4040 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.38416\n",
            "Epoch 80/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0725 - acc: 0.0484 - val_loss: 0.4138 - val_acc: 0.0526\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.38416\n",
            "Epoch 81/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0718 - acc: 0.0484 - val_loss: 0.4091 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.38416\n",
            "Epoch 82/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0713 - acc: 0.0486 - val_loss: 0.4117 - val_acc: 0.0534\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.38416\n",
            "Epoch 83/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0686 - acc: 0.0493 - val_loss: 0.4131 - val_acc: 0.0534\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.38416\n",
            "Epoch 84/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0708 - acc: 0.0489 - val_loss: 0.4139 - val_acc: 0.0527\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.38416\n",
            "Epoch 85/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0655 - acc: 0.0497 - val_loss: 0.4132 - val_acc: 0.0531\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.38416\n",
            "Epoch 86/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0672 - acc: 0.0496 - val_loss: 0.4116 - val_acc: 0.0532\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.38416\n",
            "Epoch 87/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0659 - acc: 0.0499 - val_loss: 0.4176 - val_acc: 0.0521\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.38416\n",
            "Epoch 88/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0633 - acc: 0.0506 - val_loss: 0.4078 - val_acc: 0.0531\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.38416\n",
            "Epoch 89/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0614 - acc: 0.0509 - val_loss: 0.4254 - val_acc: 0.0526\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.38416\n",
            "Epoch 90/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0617 - acc: 0.0509 - val_loss: 0.4206 - val_acc: 0.0525\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.38416\n",
            "Epoch 91/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0613 - acc: 0.0510 - val_loss: 0.4129 - val_acc: 0.0542\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.38416\n",
            "Epoch 92/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0603 - acc: 0.0511 - val_loss: 0.4138 - val_acc: 0.0543\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.38416\n",
            "Epoch 93/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0590 - acc: 0.0517 - val_loss: 0.4146 - val_acc: 0.0541\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.38416\n",
            "Epoch 94/120\n",
            "940/940 [==============================] - 31s 32ms/step - loss: 0.0565 - acc: 0.0523 - val_loss: 0.4131 - val_acc: 0.0540\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.38416\n",
            "Epoch 95/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0585 - acc: 0.0518 - val_loss: 0.4218 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.38416\n",
            "Epoch 96/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0550 - acc: 0.0527 - val_loss: 0.4292 - val_acc: 0.0523\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.38416\n",
            "Epoch 97/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0555 - acc: 0.0523 - val_loss: 0.4201 - val_acc: 0.0543\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.38416\n",
            "Epoch 98/120\n",
            "940/940 [==============================] - 31s 32ms/step - loss: 0.0550 - acc: 0.0527 - val_loss: 0.4173 - val_acc: 0.0550\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.38416\n",
            "Epoch 99/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0536 - acc: 0.0528 - val_loss: 0.4174 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.38416\n",
            "Epoch 100/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0531 - acc: 0.0527 - val_loss: 0.4265 - val_acc: 0.0534\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.38416\n",
            "Epoch 101/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0513 - acc: 0.0531 - val_loss: 0.4279 - val_acc: 0.0533\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.38416\n",
            "Epoch 102/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0500 - acc: 0.0534 - val_loss: 0.4208 - val_acc: 0.0541\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.38416\n",
            "Epoch 103/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0500 - acc: 0.0535 - val_loss: 0.4154 - val_acc: 0.0542\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.38416\n",
            "Epoch 104/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0498 - acc: 0.0537 - val_loss: 0.4275 - val_acc: 0.0538\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.38416\n",
            "Epoch 105/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0489 - acc: 0.0542 - val_loss: 0.4254 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.38416\n",
            "Epoch 106/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0477 - acc: 0.0543 - val_loss: 0.4232 - val_acc: 0.0546\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.38416\n",
            "Epoch 107/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0479 - acc: 0.0542 - val_loss: 0.4252 - val_acc: 0.0542\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.38416\n",
            "Epoch 108/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0472 - acc: 0.0545 - val_loss: 0.4272 - val_acc: 0.0526\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.38416\n",
            "Epoch 109/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0471 - acc: 0.0545 - val_loss: 0.4210 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.38416\n",
            "Epoch 110/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0447 - acc: 0.0550 - val_loss: 0.4257 - val_acc: 0.0551\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.38416\n",
            "Epoch 111/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0440 - acc: 0.0551 - val_loss: 0.4324 - val_acc: 0.0538\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.38416\n",
            "Epoch 112/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0448 - acc: 0.0550 - val_loss: 0.4350 - val_acc: 0.0528\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.38416\n",
            "Epoch 113/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0443 - acc: 0.0551 - val_loss: 0.4254 - val_acc: 0.0550\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.38416\n",
            "Epoch 114/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0419 - acc: 0.0558 - val_loss: 0.4325 - val_acc: 0.0539\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.38416\n",
            "Epoch 115/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0423 - acc: 0.0554 - val_loss: 0.4407 - val_acc: 0.0529\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.38416\n",
            "Epoch 116/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0407 - acc: 0.0559 - val_loss: 0.4323 - val_acc: 0.0546\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.38416\n",
            "Epoch 117/120\n",
            "940/940 [==============================] - 31s 33ms/step - loss: 0.0419 - acc: 0.0557 - val_loss: 0.4297 - val_acc: 0.0550\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.38416\n",
            "Epoch 118/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0410 - acc: 0.0560 - val_loss: 0.4292 - val_acc: 0.0546\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.38416\n",
            "Epoch 119/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0389 - acc: 0.0564 - val_loss: 0.4380 - val_acc: 0.0532\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.38416\n",
            "Epoch 120/120\n",
            "940/940 [==============================] - 32s 34ms/step - loss: 0.0394 - acc: 0.0563 - val_loss: 0.4369 - val_acc: 0.0536\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.38416\n",
            "\"﻿버래기\" -> \"넘치도록\"\n",
            "\"강생이\" -> \"강아지\"\n",
            "\"부각허다\" -> \"부글부글하다\"\n",
            "\"강알\" -> \"그저께\"\n",
            "\"부끄다\" -> \"부풀어 오르다\"\n",
            "\"개끔\" -> \"거품\"\n",
            "\"분시몰랑\" -> \"정황도 모르고\"\n",
            "\"개작개작\" -> \"밥을 추하게 먹는 모습\"\n",
            "\"삐암데기\" -> \"뺨\"\n",
            "\"검질\" -> \"잡초\"\n",
            "\"속슴허라\" -> \"말하지말라\"\n",
            "\"게미융허다\" -> \"희미하다\"\n",
            "\"솜쫄르멍\" -> \"숨막히는\"\n",
            "\"게작헌\" -> \"입이 큰\"\n",
            "\"쉰달이\" -> \"유산식품\"\n",
            "\"고라불켜\" -> \"고자질한다\"\n",
            "\"심토맥이\" -> \"마음 씀씀이\"\n",
            "\"곡기다\" -> \"숨막히다\"\n",
            "\"영\" -> \"이렇게\"\n",
            "\"골다\" -> \"미끄러지다\"\n",
            "\"왁왁허다\" -> \"캄캄하다\"\n",
            "\"곱지다\" -> \"숨기다\"\n",
            "\"요망지다\" -> \"똑똑하다\"\n",
            "\"과랑과랑\" -> \"햇살이 눈부시게 비추는모습\"\n",
            "\"우영밭\" -> \"텃밭\"\n",
            "\"괸당\" -> \"친족\"\n",
            "\"웃뜨리\" -> \"산간마을\"\n",
            "\"굽\" -> \"밑바닥\"\n",
            "\"재짝재짝\" -> \"걷는 모습\"\n",
            "\"기시리다\" -> \"그을리다\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1JXMOjhmRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svBej46F9y7K",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQXq3BIJzmzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "x,encoder = layers.GRU(latent_dim,dropout=0.25,recurrent_dropout=0.2, return_sequences=True, return_state=True)(x)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "\n",
        "# 디코더 생성\n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n",
        "x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "x,decoder = layers.GRU(latent_dim,dropout=0.25,recurrent_dropout=0.2, return_sequences=True, return_state=True)(x)\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbypv0zO-m0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 임베딩 사용방법\n",
        "# 참고용\n",
        "# 입력 시퀀스 정의와 처리\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
        "x, state_h, state_c = LSTM(latent_dim,\n",
        "                           return_state=True)(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# `encoder_states`를 초기 상태로 사용해 decoder를 설정\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "x = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
        "x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
        "decoder_outputs = Dense(num_decoder_tokens, activation='softmax')(x)\n",
        "\n",
        "# `encoder_input_data`와 `decoder_input_data`를 `decoder_target_data`로 반환하도록 모델을 정의\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# 컴파일 & 학습 실행\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "# `decoder_target_data`는  `decoder_input_data` 같은 정수 시퀀스보단 one-hot 인코딩 형식이 되어야 함.\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwMP_X3T-ZBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpBMqB1y-ZFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebx0ZMlTvJMJ",
        "colab_type": "text"
      },
      "source": [
        "# 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD_XvYHxfVn7",
        "colab_type": "code",
        "outputId": "ca1bb017-6538-43f7-b405-c21329e48bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "  # 손실 그래프\n",
        "  plt.plot(history.history['loss'], 'y', label='train loss')\n",
        "  plt.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # 정확도 그래프\n",
        "  plt.plot(history.history['acc'], 'y', label='train acc')\n",
        "  plt.plot(history.history['val_acc'], 'r', label='val acc')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSChga6UUkFCA10ppYKEBrpSSgWJ/weSIUG9i5yemgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOE30Sinl4zTRK6WUj/v/TLk2Zlw6bywAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ5Sx8GZVq6T",
        "colab_type": "text"
      },
      "source": [
        "모델불러오고 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odtxgzYXVqey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7puwJOTU8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUL-DOIIU6zS",
        "colab_type": "code",
        "outputId": "9957facb-cc2b-4af7-869e-25d9f58f6d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "import matplotlib\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "batch_size = 32  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "def RepeatVectorLayer(rep, axis):\n",
        "  return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis),\n",
        "                      lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n",
        "\n",
        "# 인코더 생성\n",
        "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n",
        "encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h = encoder(encoder_inputs)\n",
        "\n",
        "# 디코더 생성\n",
        "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n",
        "decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
        "\n",
        "# attention 생성\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh')\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "dense2_t_score_layer = layers.Dense(1)\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs)\n",
        "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh')\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(attention_output)\n",
        "################### model\n",
        "from keras.models import load_model\n",
        "history = load_model('/content/atten_GRU_weight_g.h5')\n",
        "###################\n",
        "encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h])\n",
        "encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim))\n",
        "\n",
        "decoder_inputs = layers.Input(shape=(1, num_decoder_tokens))\n",
        "decoder_state_input_h = layers.Input(shape=(latent_dim,))\n",
        "decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h)\n",
        "\n",
        "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n",
        "repeat_d = repeat_d_layer(decoder_outputs)\n",
        "\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(encoder_outputs_input)\n",
        "\n",
        "concat_for_score_layer = layers.Concatenate(axis=-1)\n",
        "concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n",
        "\n",
        "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n",
        "dense1_score = dense1_score_layer(concat_for_score)\n",
        "\n",
        "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n",
        "dense2_score = dense2_score_layer(dense1_score)\n",
        "dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score)\n",
        "\n",
        "softmax_score_layer = layers.Softmax(axis=-1)\n",
        "softmax_score = softmax_score_layer(dense2_score)\n",
        "\n",
        "repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n",
        "repeat_score = repeat_score_layer(softmax_score)\n",
        "\n",
        "permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n",
        "repeat_e_layer = RepeatVectorLayer(1, axis=1)\n",
        "repeat_e = repeat_e_layer(permute_e)\n",
        "\n",
        "attended_mat_layer = layers.Multiply()\n",
        "attended_mat = attended_mat_layer([repeat_score, repeat_e])\n",
        "\n",
        "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n",
        "                             lambda x: tuple(x[:-1]))\n",
        "context = context_layer(attended_mat)\n",
        "\n",
        "concat_context_layer = layers.Concatenate(axis=-1)\n",
        "concat_context = concat_context_layer([context, decoder_outputs])\n",
        "\n",
        "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n",
        "attention_output = attention_output_layer(concat_context)\n",
        "\n",
        "decoder_att_outputs = decoder_dense(attention_output)\n",
        "\n",
        "decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input],\n",
        "                            [decoder_outputs, decoder_h, decoder_att_outputs])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 1203\n",
            "Number of unique input tokens: 787\n",
            "Number of unique output tokens: 749\n",
            "Max sequence length for inputs: 165\n",
            "Max sequence length for outputs: 183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYQDRTk3yz4r",
        "colab_type": "code",
        "outputId": "8db2093c-ec63-4123-eced-0bfa79afac2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "enc_outputs, states_value = encoder_model.predict(encoder_input_data[2:3])\n",
        "print(enc_outputs)\n",
        "print()\n",
        "print(states_value)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0.0845568  -0.04223287  0.01504657 ... -0.01675112  0.01217361\n",
            "   -0.07913809]\n",
            "  [-0.01012469 -0.04554577  0.07890618 ... -0.00401536 -0.00055613\n",
            "   -0.10650092]\n",
            "  [-0.06501827  0.05378567  0.2214259  ... -0.02666245 -0.05511926\n",
            "   -0.14034012]\n",
            "  ...\n",
            "  [ 0.09179988  0.02620946 -0.1362757  ...  0.20895988 -0.19421019\n",
            "   -0.08369055]\n",
            "  [ 0.09182352  0.02621309 -0.13627124 ...  0.20896643 -0.19420826\n",
            "   -0.08371452]\n",
            "  [ 0.09184714  0.02621309 -0.1362681  ...  0.20896728 -0.19420315\n",
            "   -0.08373799]]]\n",
            "\n",
            "[[ 9.18471441e-02  2.62130871e-02 -1.36268094e-01 -6.08358458e-02\n",
            "  -7.28430599e-02  1.69694096e-01 -1.23323165e-02  7.65081495e-02\n",
            "   3.10718752e-02 -1.84719614e-03  1.00338481e-01  3.34279910e-02\n",
            "   3.96817364e-02 -1.35956854e-01 -1.39421657e-01 -3.15561518e-02\n",
            "  -5.76024204e-02 -6.05241433e-02  4.81434584e-01 -1.32362813e-01\n",
            "   3.27997003e-03 -8.01443495e-03 -1.85289495e-02 -1.41692251e-01\n",
            "  -1.06842995e-01  5.45921910e-04  3.87596935e-01  6.03721961e-02\n",
            "   8.07228014e-02  3.64684537e-02  6.18462488e-02 -3.01507413e-01\n",
            "   6.04353547e-02 -7.76714385e-02  8.05897266e-03  1.32232606e-01\n",
            "  -2.29691058e-01 -4.98210862e-02 -2.38389224e-02  1.56470120e-01\n",
            "   6.38743164e-03  3.33776698e-03  2.15708166e-01 -4.40563895e-02\n",
            "   1.10457890e-01  2.38315105e-01 -6.23930581e-02  5.62002882e-02\n",
            "   7.72832111e-02 -5.39433174e-02  3.63828987e-02 -9.58689675e-02\n",
            "   1.84071869e-01 -1.66121677e-01 -3.39908972e-02 -2.15133131e-01\n",
            "   7.14138970e-02 -3.09865996e-02  8.90992209e-02  1.21591933e-01\n",
            "  -8.37342814e-02  1.47961497e-01  6.88679591e-02 -1.00608014e-01\n",
            "  -5.67902171e-04 -6.49102440e-05 -9.97563638e-03  3.03351164e-01\n",
            "   1.66438043e-01 -2.06658304e-01 -5.07169962e-02  8.32277834e-02\n",
            "  -8.44014995e-03  3.11356708e-02  2.02999890e-01  3.80575687e-01\n",
            "   2.49356270e-01 -1.85453385e-01 -1.56539418e-02  1.61208510e-02\n",
            "  -1.16894118e-01 -1.70623348e-03 -1.91666603e-01  2.00133383e-01\n",
            "  -1.40919417e-01 -3.46512422e-02 -2.42267526e-03  1.05558652e-02\n",
            "   7.01953471e-02 -1.26980543e-01  1.37789950e-01  3.16646285e-02\n",
            "   6.61833510e-02  8.30543041e-02  3.50542888e-02 -4.35679965e-02\n",
            "   4.84781377e-02  8.51513594e-02  2.07637280e-01  1.66170165e-01\n",
            "  -2.58929674e-02  5.60409687e-02  3.92889827e-02  1.90010052e-02\n",
            "  -5.54189011e-02  2.54782364e-02 -4.24576737e-02  3.20782326e-02\n",
            "   5.26398756e-02  5.21192327e-03  7.30864587e-04 -1.02668539e-01\n",
            "  -7.57500231e-02  4.47970033e-02 -1.00827888e-01 -4.71055880e-02\n",
            "  -2.28769388e-02  4.21066850e-01 -1.52236193e-01  5.47476485e-02\n",
            "   1.60006918e-02 -6.64427280e-02  7.25652948e-02  3.81450504e-02\n",
            "  -4.35017515e-03  2.17028093e-02  1.02061760e-02 -1.68222889e-01\n",
            "  -1.52572691e-01 -2.58231796e-02  3.30447331e-02 -7.59621263e-02\n",
            "  -1.37626305e-01 -4.94327247e-02 -2.87606232e-02 -1.19385913e-01\n",
            "   1.11554191e-02  3.02720964e-01 -5.11564091e-02  7.41369370e-03\n",
            "  -1.62335008e-01  4.87262011e-02 -5.91877177e-02  4.73358892e-02\n",
            "  -4.67050970e-02 -1.11307308e-01 -1.66128114e-01 -8.15205723e-02\n",
            "  -1.14731282e-01  1.62780270e-01 -1.95625350e-01  9.88608599e-02\n",
            "   3.91380116e-02 -3.30329202e-02  7.03968480e-03 -2.11861625e-01\n",
            "  -1.73475891e-01 -4.60696109e-02  4.97804210e-03 -2.86249518e-01\n",
            "  -2.32184887e-01 -3.17064933e-02 -6.89055622e-02  1.84144378e-01\n",
            "   9.26086679e-02  1.44372853e-02 -1.06695279e-01 -5.99997267e-02\n",
            "   6.59822971e-02 -1.35351326e-02  6.56801909e-02 -8.86300951e-02\n",
            "  -7.00306445e-02  6.67676851e-02 -6.01751767e-02  1.09740719e-01\n",
            "   6.46574562e-03  3.28110754e-01 -1.63401157e-01 -1.12513311e-01\n",
            "   1.28691763e-01  9.86647755e-02  4.48322073e-02 -2.18776595e-02\n",
            "   9.25635174e-03 -1.37545094e-01  1.59236267e-01 -1.90956488e-01\n",
            "  -2.20924735e-01 -3.53857577e-02  2.75073886e-01 -2.45391399e-01\n",
            "  -1.01602763e-01 -4.96193953e-02  9.15436149e-02 -1.08572736e-01\n",
            "   8.92296582e-02  8.36705789e-02 -3.86312485e-01  2.38839090e-02\n",
            "   2.87341196e-02 -6.95853680e-02 -1.90594792e-01  1.01653501e-01\n",
            "   1.12030365e-01 -7.86008313e-02  6.46999106e-02 -1.73732951e-01\n",
            "   1.18991658e-01 -3.19677554e-02  9.33487043e-02  6.57879785e-02\n",
            "  -7.43617415e-02 -5.83736598e-02 -3.25249061e-02 -1.73416764e-01\n",
            "   2.19107389e-01  1.95692778e-01 -7.86744505e-02  1.26054004e-01\n",
            "  -7.62614012e-02 -2.13176742e-01 -2.38743141e-01  1.62854835e-01\n",
            "   1.29453288e-02  4.04490232e-02 -1.42958462e-01 -1.33307904e-01\n",
            "  -3.30790989e-02 -4.91285957e-02 -1.44636026e-02  2.60626078e-01\n",
            "   1.63212493e-01 -2.19912782e-01  2.57921014e-02  8.73038024e-02\n",
            "  -7.52206966e-02 -1.60397604e-01  1.05496019e-01  9.22601819e-02\n",
            "  -1.28820330e-01  1.82020152e-03  5.71692586e-02 -4.98069031e-03\n",
            "  -3.05308439e-02 -1.23219583e-02  2.07211673e-02  3.78815502e-01\n",
            "  -1.34695843e-01  8.47664550e-02  7.40507394e-02 -3.68028395e-02\n",
            "  -8.72248188e-02  2.08967283e-01 -1.94203153e-01 -8.37379918e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDe7X2LKUonT",
        "colab_type": "code",
        "outputId": "bac68696-bf1c-4797-8560-4d56306f7a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        }
      },
      "source": [
        "# def decode_sequence(input_seq):\n",
        "#   # 입력 문장을 인코딩\n",
        "#   enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "#   # 디코더의 입력으로 쓸 단일 문자\n",
        "#   target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#   # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "#   target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "#   # 문장 생성\n",
        "#   stop_condition = False\n",
        "#   decoded_sentence = ''\n",
        "#   while not stop_condition:\n",
        "#     # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "#     # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "#     dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "#         [target_seq, states_value, enc_outputs])\n",
        " \n",
        "#     # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "#     sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "#     sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "#     decoded_sentence += sampled_char\n",
        " \n",
        "#     # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "#     if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "#       stop_condition = True\n",
        " \n",
        "#     # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "#     target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "#     target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "#     states_value = h\n",
        " \n",
        "#   return decoded_sentence\n",
        "\n",
        "for seq_index in range(10,1000,20):\n",
        "  input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"속슴허라\" -> \"말하지말라\"\n",
            "\"기시리다\" -> \"초벌로 불에 태우다\"\n",
            "\"모소완\" -> \"무서워\"\n",
            "\"물옷\" -> \"잠수복\"\n",
            "\"어멍 \" -> \"어머니\"\n",
            "\"또꼬망 \" -> \"똥구멍\"\n",
            "\"돗괴기 \" -> \"돼지고기\"\n",
            "\"단취 \" -> \"단추\"\n",
            "\"시미옷 \" -> \"손자용상복\"\n",
            "\"요령 \" -> \"방울\"\n",
            "\"작박 \" -> \"작은바가지\"\n",
            "\"잠데 \" -> \"쟁기\"\n",
            "\"물꾸럭 \" -> \"문어\"\n",
            "\"감저 \" -> \"고구마\"\n",
            "\"멘도롱호다 \" -> \"따뜻하다\"\n",
            "\"얼랍지다 \" -> \"당황하다\"\n",
            "\"데싸지다 \" -> \"자빠지다\"\n",
            "\"데껴불다 \" -> \"던져버리다\"\n",
            "\"일고  \" -> \"일곱\"\n",
            "\"통시 \" -> \"화장실\"\n",
            "\"먹엄직이 살암직이 시상\" -> \"먹어 볼만한 살아 볼만한 세상\"\n",
            "\"모멀고루 풀엉 얄룹게 지졍\" -> \"메밀가루 반죽하여 얇게 지져\"\n",
            "\"고루삭삭 삐어지국\" -> \"사방으로 흩어지고\"\n",
            "\"경해그네 어떵 되연\" -> \"그래서 어떻게 되었어\"\n",
            "\"정 골아도 빙세기 웃곡\" -> \"저렇게 말해도 빙그레 웃고\"\n",
            "\"말 골암쩌\" -> \"말을 하네\"\n",
            "\"이래 도라앉작 저래 도라앉작\" -> \"이리 흔들리고 저리 흔들리고\"\n",
            "\"아고 삼촌 물꾸럭 나 얼마마씸?\" -> \"아고 삼촌 문어 한마리 얼마죠?\"\n",
            "\"갭인년 숭년에도 먹당 남은 게 물이여\" -> \"갑이년 흉년에도 먹다 남은 게 물이다.\"\n",
            "\"고튼 품이민 홀어멍 칩 머슴산다.\" -> \"같은 값이면 과부집 머슴을 산다.\"\n",
            "\"끅 걷으레 간 놈이 정당 벌립 망 돌른다.\" -> \"칡 걷으러 간 놈이 정당벌레 테 엮는다.\"\n",
            "\"놈이 쉐 들럭키는 건 보기 좋나.\" -> \"남의 소 날뛰는 건 보기 좋다.\"\n",
            "\"남편 옆에 같이 앉으세요\" -> \"서방 조끝에 고치 앉즙써\"\n",
            "\"참말로 이쁘고 둥실둥실합니다\" -> \"촘말로 곱고 몬트락허우다\"\n",
            "\"제주도 오잰하난 폭삭 속아수다\" -> \"제주도 오느라 수고하셨어요\"\n",
            "\"삼성혈가잰하는디예\" -> \"삼성혈에 가려는데요\"\n",
            "\"곱들락 호게 몬뜰락 벗엉 옵서\" -> \"아름답게 모조리 벗어서 오십시오\"\n",
            "\"귀 눈이 왁왁하우다.\" -> \"귀와 눈이 캄캄합니다\"\n",
            "\"제주도엔 보름이 많이 있수다.\" -> \"제주도에는 바람이 많이 있습니다.\"\n",
            "\"`기여, 느영 나영 두리 둥실 소랑호게.`\" -> \"`그래, 너하고 나하고 둘이 둥실 사랑하자.`\"\n",
            "\"욕은 고냉이 밤눈 어둡덴 혼다.\" -> \"약은 고양이가 밤눈이 어둡다고 한다.\"\n",
            "\"똣똣혼 게 먹기 똑 좋았수다.\" -> \"따끈따끈한 것이 먹기에 꼭 좋았습니다.\"\n",
            "\"게메 마씸, 그런 사롬이 어디 있수과?\" -> \"그러게 말입니다, 그런 사람이 어디 있습니까?\"\n",
            "\"서울서 족은 아방네 완 마씀.\" -> \"서울에서 작은 아버지네가 왔습니다.\"\n",
            "\"왕, 방 삽서.\" -> \"와서 보고 사십시오.\"\n",
            "\"안트레 들어 왕.\" -> \"안으로 들어 오셔서.\"\n",
            "\"어떵 생겨서?\" -> \"어떻게 생겼던가?\"\n",
            "\"게도, 놈 호고 싸울 땐.\" -> \"그래도, 남하고 싸울 때는.\"\n",
            "\"경 혼다.\" -> \"그러면 말하게 자오.\"\n",
            "\"사롬 몸은 곱닥해사 혼다.\" -> \"사람 다시집 사람 정으면 가면 속 보니다.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ4PFBTpSr0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrKRwrR3Tppv",
        "colab_type": "text"
      },
      "source": [
        "테스트셋 만들기."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yegVgDMzfbdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOCte51Zf5Yu",
        "colab_type": "code",
        "outputId": "dd118f9b-ebec-45ff-fb7c-e670d9aecd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "input_texts\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeff버래기',\n",
              " '바당에 괴기 사레 마씀',\n",
              " '무사 누게 왔수과',\n",
              " '서울서 족은 아방네 완 마씀',\n",
              " '게민 멩심허영 갔당 옵서',\n",
              " '고랑은 몰라 마씀',\n",
              " '제주도에 왕 봐사 알아짐니다',\n",
              " '돌도 많고 보롬도 많고 비바리도 많고',\n",
              " '유채꽃도 곱드락 호게 피었수다']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwmKB6pkSsn7",
        "colab_type": "code",
        "outputId": "d8474768-f6d4-4461-d617-41a26aa2a663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# 테스트 데이터 셋 만들기\n",
        "\n",
        "from keras import layers, models\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Bidirectional\n",
        "import numpy as np\n",
        "from keras import datasets\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from matplotlib import ticker\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data_path = '/content/test.txt'\n",
        "\n",
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text = line.split('\\t')\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "# 전처리\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
        "\n",
        "\n",
        "# 문자 -> 숫자 변환용 사전\n",
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "# 학습에 사용할 데이터를 담을 3차원 배열\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "\n",
        "# 숫자 -> 문자 변환용 사전\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 9\n",
            "Number of unique input tokens: 62\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3OWr5U-e1dV",
        "colab_type": "code",
        "outputId": "e75b7990-01c6-405e-d778-c798b2c546b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력 문장을 인코딩\n",
        "  enc_outputs, states_value = encoder_model.predict(input_seq)\n",
        " \n",
        "  # 디코더의 입력으로 쓸 단일 문자\n",
        "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "  # 첫 입력은 시작 문자인 '\\t'로 설정\n",
        "  target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        " \n",
        "  # 문장 생성\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "    # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n",
        "    # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n",
        "    dec_outputs, h, output_tokens = decoder_model.predict(\n",
        "        [target_seq, states_value, enc_outputs])\n",
        " \n",
        "    # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        " \n",
        "    # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n",
        "    if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "      stop_condition = True\n",
        " \n",
        "    # 디코더의 다음 입력으로 쓸 데이터 갱신\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, sampled_token_index] = 1.\n",
        "    \n",
        "    states_value = h\n",
        " \n",
        "  return decoded_sentence\n",
        "\n",
        "for seq_index in range(9):\n",
        "  input_seq = encoder_input_data_test[seq_index: seq_index + 1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-07cfbd166981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input_data_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"{}\" -> \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-07cfbd166981>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# 입력 문장을 인코딩\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# 디코더의 입력으로 쓸 단일 문자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (165, 787) but got array with shape (20, 62)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRr-uZL4e1hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP-PbxIwe1kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCh33atHwvI2",
        "colab_type": "code",
        "outputId": "5591393b-adab-4a2a-e69c-1f7553a29e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder_model.predict(encoder_input_data[1:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.0000000e+00, -0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.6329135e-01,\n",
              "          6.4644217e-04, -0.0000000e+00, -9.2373818e-02,  2.9097532e-28,\n",
              "         -0.0000000e+00, -8.5620570e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -9.6190804e-01,  0.0000000e+00,  1.4762883e-31,  0.0000000e+00,\n",
              "         -2.5769413e-02, -1.5891892e-01,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -4.8811927e-01, -5.2259541e-01,\n",
              "          2.4740072e-01,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -4.8581851e-03, -1.8517128e-01, -0.0000000e+00, -4.0916356e-01,\n",
              "          0.0000000e+00, -9.0105736e-01, -0.0000000e+00,  5.5774748e-03,\n",
              "         -2.9330635e-01, -9.8345417e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,  3.7912405e-01,\n",
              "         -8.5560732e-02, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -2.9002559e-01, -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  7.6037529e-03,  0.0000000e+00, -0.0000000e+00,\n",
              "          9.0489155e-01,  2.0254247e-01,  0.0000000e+00,  4.6030561e-23,\n",
              "          0.0000000e+00,  0.0000000e+00, -7.6174669e-02, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -0.0000000e+00,  2.5714195e-01,\n",
              "          8.8205129e-02, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00, -4.2958260e-02, -4.8764575e-01,\n",
              "         -0.0000000e+00,  0.0000000e+00,  4.7477731e-01,  8.6879867e-01,\n",
              "          1.1599462e-02,  0.0000000e+00,  9.0954005e-04, -1.2454973e-01,\n",
              "          0.0000000e+00,  0.0000000e+00,  9.9968106e-01, -9.1520578e-02,\n",
              "          7.9044974e-01, -2.3096931e-01,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  4.7353655e-01,  4.7984362e-02, -6.8209851e-01,\n",
              "          0.0000000e+00, -7.3482305e-01, -8.5555112e-31, -5.8489289e-02,\n",
              "          0.0000000e+00,  1.3068425e-05, -0.0000000e+00, -5.5376284e-02,\n",
              "         -0.0000000e+00,  0.0000000e+00, -0.0000000e+00, -9.4534010e-02,\n",
              "         -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -9.4223726e-01, -4.8242757e-01, -0.0000000e+00,\n",
              "          1.2427284e-01,  0.0000000e+00,  6.2701292e-02, -9.9980128e-01,\n",
              "         -1.8277472e-01, -5.0021201e-02,  0.0000000e+00,  6.6289696e-04,\n",
              "          0.0000000e+00, -3.8783801e-01, -0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00, -1.9770602e-02,  0.0000000e+00, -9.9869603e-01,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -2.7131078e-01,\n",
              "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.6902500e-01,\n",
              "          0.0000000e+00, -1.5806250e-02,  0.0000000e+00,  0.0000000e+00,\n",
              "          5.6324024e-37,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          2.4540097e-02,  7.3298591e-01, -1.1825219e-01, -0.0000000e+00,\n",
              "         -4.2891189e-01, -1.8483192e-02, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -0.0000000e+00, -7.6095667e-04,  0.0000000e+00,\n",
              "          3.3993727e-01, -1.1197328e-01, -3.5808769e-01, -0.0000000e+00,\n",
              "         -0.0000000e+00,  5.7189941e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "          1.0680524e-01, -0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -6.4338589e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -9.7646445e-01,  0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "         -4.5837779e-03,  0.0000000e+00, -0.0000000e+00,  0.0000000e+00,\n",
              "          0.0000000e+00, -7.2626758e-01,  1.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  0.0000000e+00,  1.8077916e-01, -0.0000000e+00,\n",
              "         -0.0000000e+00,  3.1599915e-01, -7.0703638e-01,  0.0000000e+00,\n",
              "          0.0000000e+00, -3.6475569e-01,  0.0000000e+00,  0.0000000e+00,\n",
              "         -0.0000000e+00,  2.0247820e-01,  9.1961674e-02, -1.0000000e+00,\n",
              "         -0.0000000e+00, -0.0000000e+00, -0.0000000e+00, -4.7337539e-03,\n",
              "         -0.0000000e+00, -0.0000000e+00,  3.1825322e-01,  0.0000000e+00,\n",
              "          3.3561704e-03,  0.0000000e+00,  9.5703237e-02, -9.9436027e-01,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -6.5144464e-05,\n",
              "         -0.0000000e+00,  1.5679682e-02,  0.0000000e+00, -0.0000000e+00,\n",
              "         -0.0000000e+00,  4.9511697e-02,  8.6975589e-02,  2.4072388e-01,\n",
              "          1.7965989e-30,  0.0000000e+00, -0.0000000e+00,  2.3980862e-02,\n",
              "         -0.0000000e+00, -0.0000000e+00,  0.0000000e+00, -0.0000000e+00,\n",
              "          0.0000000e+00,  0.0000000e+00, -5.6163829e-02, -9.9846846e-01]],\n",
              "       dtype=float32),\n",
              " array([[ 0.00000000e+00, -0.00000000e+00, -2.98531342e+01,\n",
              "          0.00000000e+00,  0.00000000e+00,  5.01047707e+01,\n",
              "          1.34669174e+02,  2.75115460e-01,  7.64443817e+01,\n",
              "         -1.37504721e+00, -4.31306332e-01,  5.30959675e-28,\n",
              "         -9.65302825e-01, -1.76891494e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.97083485e+00,  0.00000000e+00,\n",
              "          3.09288409e-31,  3.63989830e+00, -1.22796074e+02,\n",
              "         -1.06463289e+01,  0.00000000e+00, -0.00000000e+00,\n",
              "          0.00000000e+00,  1.52326233e+02, -6.13411427e-01,\n",
              "         -1.31800199e+00,  5.11115372e-01,  3.95650327e-01,\n",
              "          4.47818041e+00,  0.00000000e+00, -2.82499511e-02,\n",
              "         -1.50106781e+02, -9.98390656e+01, -9.97066736e-01,\n",
              "          0.00000000e+00, -1.47781253e+00, -1.52559143e+02,\n",
              "          5.97162971e+01, -1.15213966e+00, -6.47213936e+00,\n",
              "          3.40338945e+00,  5.45292816e+01, -1.35125923e+00,\n",
              "          0.00000000e+00, -9.55139637e+00,  5.35434306e-01,\n",
              "         -4.20049953e+00, -0.00000000e+00,  8.07391281e+01,\n",
              "         -0.00000000e+00, -1.34347717e+02, -2.83787346e+00,\n",
              "          8.53425522e+01,  1.00287371e+01, -0.00000000e+00,\n",
              "          3.89394760e-02,  7.21604767e+01, -2.84739571e+01,\n",
              "          1.49858141e+00,  8.66559505e-01,  0.00000000e+00,\n",
              "          5.27181764e-23,  0.00000000e+00,  0.00000000e+00,\n",
              "         -2.94841194e+00, -2.42356211e-01,  7.82024956e+00,\n",
              "          0.00000000e+00, -2.48831773e+00,  2.10909100e+01,\n",
              "          1.51339096e+02, -7.86861944e+00,  0.00000000e+00,\n",
              "         -1.09752560e+00, -8.30106125e+01,  1.05638433e+00,\n",
              "         -1.44126923e+02, -1.39781160e+01, -0.00000000e+00,\n",
              "          0.00000000e+00,  9.87113647e+01,  4.58214712e+00,\n",
              "          3.48192382e+00,  0.00000000e+00,  9.85414684e-02,\n",
              "         -5.12531340e-01,  1.79604130e+01,  1.56015730e+01,\n",
              "          4.37174606e+00, -3.79684687e-01,  1.07262921e+00,\n",
              "         -7.01352775e-01,  0.00000000e+00, -7.02870488e-01,\n",
              "          4.47108955e+01,  1.00930511e+02,  0.00000000e+00,\n",
              "         -6.31350219e-01,  1.52941370e+00,  1.47939575e+02,\n",
              "          9.42515259e+01, -7.03328323e+00,  1.59019928e+01,\n",
              "         -1.40816402e+00, -1.14104644e-30, -4.34135765e-01,\n",
              "          5.03126860e-01,  3.51720482e-05, -6.04815602e-01,\n",
              "         -2.18326032e-01, -1.26794418e+02,  1.80413389e+00,\n",
              "         -1.26950867e+02, -2.67322235e+01, -1.13064095e-01,\n",
              "          0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "          0.00000000e+00, -1.75762594e+00, -7.57123709e-01,\n",
              "         -0.00000000e+00,  5.61144233e-01,  4.04905224e+00,\n",
              "          5.16400814e-01, -4.60827446e+00, -4.16803002e-01,\n",
              "         -1.49123383e+02,  3.38845491e+00,  3.63321020e-03,\n",
              "          0.00000000e+00, -7.07973862e+01, -1.48403478e+00,\n",
              "         -4.20976996e-01, -9.46586132e-01, -5.55929899e+00,\n",
              "          0.00000000e+00, -3.66741586e+00, -1.50491745e+02,\n",
              "         -1.30656372e+02,  1.25606880e+02, -6.02356613e-01,\n",
              "          8.84825349e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "          5.57098269e-01,  2.85795659e-01, -7.32855141e-01,\n",
              "          1.58492327e+00,  0.00000000e+00,  1.47897632e-36,\n",
              "          0.00000000e+00, -8.95267391e+00,  4.56423424e-02,\n",
              "         -6.76231384e-01,  1.21814432e+01,  0.00000000e+00,\n",
              "          6.62447023e+00, -6.24138975e+00, -1.23128414e+00,\n",
              "          1.51434036e+02, -1.85090661e-01,  1.33262224e+01,\n",
              "          9.35149908e-01, -8.43520508e+01, -0.00000000e+00,\n",
              "         -1.87059665e+00, -1.36203461e+02, -1.15526062e+02,\n",
              "          0.00000000e+00,  0.00000000e+00, -5.28743744e+00,\n",
              "         -4.28142399e-03,  0.00000000e+00,  5.57438431e+01,\n",
              "         -1.12444803e-01, -7.98213363e-01, -3.45038652e-01,\n",
              "         -9.80087146e-02,  1.07140183e+00,  0.00000000e+00,\n",
              "          1.19289026e+01,  8.01095104e+00, -1.92479014e+00,\n",
              "          2.59952545e+00,  1.58299446e+00,  0.00000000e+00,\n",
              "         -2.12397432e+00,  0.00000000e+00,  5.42274475e-01,\n",
              "         -2.21527672e+00,  0.00000000e+00,  1.75964146e+01,\n",
              "         -2.75903702e+00, -1.19178796e+00,  0.00000000e+00,\n",
              "         -3.62383866e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         -7.28727102e+00,  1.40233490e+02,  1.38978500e+02,\n",
              "         -1.32205475e+02,  0.00000000e+00,  1.07438957e+02,\n",
              "         -1.68638859e+01, -1.54776020e+01,  5.51546693e-01,\n",
              "         -3.50762100e+01,  3.59794855e+00,  0.00000000e+00,\n",
              "         -1.29502472e+02,  0.00000000e+00,  1.01906616e+02,\n",
              "         -1.14045391e+01,  3.80389661e-01,  5.82386672e-01,\n",
              "         -2.35989819e+01, -0.00000000e+00, -0.00000000e+00,\n",
              "         -6.28876114e+00, -1.21654216e-02, -0.00000000e+00,\n",
              "         -1.35992233e+02,  5.54244578e-01,  0.00000000e+00,\n",
              "          6.99225161e-03,  5.47310486e+01,  1.03944087e+00,\n",
              "         -2.93411875e+00, -7.10304642e+00, -0.00000000e+00,\n",
              "          0.00000000e+00, -1.34732662e-04, -1.46412430e+01,\n",
              "          2.07393646e+00,  0.00000000e+00, -5.52425041e+01,\n",
              "         -4.39005566e+00,  1.45118043e-01,  2.00735474e+00,\n",
              "          1.41495163e+02,  2.80820861e-30,  1.17513478e-01,\n",
              "         -2.34038830e-01,  3.31161946e-01, -7.67882442e+00,\n",
              "         -9.32745590e+01,  2.23502254e+01, -1.27744579e+01,\n",
              "          0.00000000e+00,  2.05016117e+01, -7.43866488e-02,\n",
              "         -3.58693957e+00]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ3WbpinoRgH",
        "colab_type": "code",
        "outputId": "e057efd1-d414-45b8-c3ae-35fd3f9822a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.history.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.90837691092862,\n",
              "  0.9354104222362614,\n",
              "  0.9352390464916024,\n",
              "  0.9354153230626095,\n",
              "  0.9354104250135388,\n",
              "  0.9354104203135309,\n",
              "  0.9354104260817223,\n",
              "  0.9354985636194975,\n",
              "  0.9354740763650573,\n",
              "  0.9357874575054347,\n",
              "  0.9370115768952182,\n",
              "  0.9379859761097953,\n",
              "  0.9379174260682958,\n",
              "  0.9392345844631127,\n",
              "  0.9392052049277931,\n",
              "  0.9407378007861449,\n",
              "  0.9414135181348383,\n",
              "  0.9425886760475815,\n",
              "  0.94316646681037,\n",
              "  0.9442583754071198,\n",
              "  0.9448704377724706,\n",
              "  0.945830150530757,\n",
              "  0.9463393848429444,\n",
              "  0.9472452385023931,\n",
              "  0.9479160537429181,\n",
              "  0.9490373484977257,\n",
              "  0.9495367941890566,\n",
              "  0.9505209937745098,\n",
              "  0.9513484948852157,\n",
              "  0.9521123431489459,\n",
              "  0.952788058574909,\n",
              "  0.9535029479252395,\n",
              "  0.9545067294524134,\n",
              "  0.9551873378001661,\n",
              "  0.9555986517219133,\n",
              "  0.9564947028741188,\n",
              "  0.9572438636133748,\n",
              "  0.9581693034872787,\n",
              "  0.9589380525773571,\n",
              "  0.9600250680386806,\n",
              "  0.9607056838637185,\n",
              "  0.9617731156742274,\n",
              "  0.9628699238155051,\n",
              "  0.9635407493105926,\n",
              "  0.9643927425893831,\n",
              "  0.9656119639300959,\n",
              "  0.9662093338573278,\n",
              "  0.9673306288257721,\n",
              "  0.9682854411849838,\n",
              "  0.9693332959674166,\n",
              "  0.9702979027156762,\n",
              "  0.9709491358008436,\n",
              "  0.9718402938176227,\n",
              "  0.9728587699192827,\n",
              "  0.9735638546260027,\n",
              "  0.9750034322020829,\n",
              "  0.9753266011087698,\n",
              "  0.9763058887587653,\n",
              "  0.9772019497382598,\n",
              "  0.9780343557344116,\n",
              "  0.9786317256616435,\n",
              "  0.9775593919566028,\n",
              "  0.9804727996976572,\n",
              "  0.9809379712227853,\n",
              "  0.9807323230210171,\n",
              "  0.9815059616146976,\n",
              "  0.9820298909286445,\n",
              "  0.9826272614967866,\n",
              "  0.983200155919598,\n",
              "  0.9838073153222333,\n",
              "  0.9843067580226502,\n",
              "  0.9844830275436456,\n",
              "  0.9850706022272828,\n",
              "  0.9854574263309492,\n",
              "  0.9859127979124745,\n",
              "  0.9859519750413929,\n",
              "  0.9863485916113768,\n",
              "  0.9866374837882202,\n",
              "  0.9869459647431595,\n",
              "  0.9870928637015777,\n",
              "  0.9873034133706041,\n",
              "  0.9874649953671254,\n",
              "  0.9877979580219501,\n",
              "  0.9881309202495014,\n",
              "  0.9882043713309859,\n",
              "  0.9882729111179229,\n",
              "  0.9884149111727233,\n",
              "  0.988522636847684,\n",
              "  0.9881896669292108,\n",
              "  0.9888262088580798,\n",
              "  0.9888360090153192,\n",
              "  0.9890808236641696,\n",
              "  0.9890808277232672,\n",
              "  0.9892375140207216,\n",
              "  0.9892571047215479,\n",
              "  0.9891395863666329,\n",
              "  0.9892522053906567,\n",
              "  0.9893550225483474,\n",
              "  0.9895606775864906,\n",
              "  0.9896292286961736],\n",
              " 'loss': [1.0096772083458507,\n",
              "  0.4459582566146782,\n",
              "  0.5313804481832785,\n",
              "  0.45794955141655436,\n",
              "  0.4284211137602406,\n",
              "  0.43195175376844236,\n",
              "  0.4269149436959229,\n",
              "  0.4198300125991999,\n",
              "  0.40419935496477244,\n",
              "  0.38667374582273556,\n",
              "  0.40547882933770457,\n",
              "  0.35477240901694074,\n",
              "  0.38163947621126754,\n",
              "  0.34341190418889445,\n",
              "  0.3816452809345765,\n",
              "  0.32727003749126177,\n",
              "  0.34477989936387665,\n",
              "  0.31009486867749136,\n",
              "  0.3107977184770782,\n",
              "  0.296052504397635,\n",
              "  0.353442058875142,\n",
              "  0.2829253629757939,\n",
              "  0.2789535340869726,\n",
              "  0.2722864289864844,\n",
              "  0.26841296271611287,\n",
              "  0.25975411120922337,\n",
              "  0.2558082861285056,\n",
              "  0.2514205320761623,\n",
              "  0.2440831141018953,\n",
              "  0.23859162762173616,\n",
              "  0.23346964635729361,\n",
              "  0.23040057777503914,\n",
              "  0.22234650623841098,\n",
              "  0.21799792605702595,\n",
              "  0.21396246621899281,\n",
              "  0.2089877690465647,\n",
              "  0.20390964910975493,\n",
              "  0.19830190708133055,\n",
              "  0.19320864094200954,\n",
              "  0.18858892174177272,\n",
              "  0.18335340911769524,\n",
              "  0.17914873393633032,\n",
              "  0.17309058684602005,\n",
              "  0.1693868309686688,\n",
              "  0.16545846102271883,\n",
              "  0.15966681254807338,\n",
              "  0.15639500052911834,\n",
              "  0.15184295978597415,\n",
              "  0.14713666884488957,\n",
              "  0.14274392450582168,\n",
              "  0.13894881623192928,\n",
              "  0.13497098740924643,\n",
              "  0.13157488849000692,\n",
              "  0.12706793801972516,\n",
              "  0.12411574992654999,\n",
              "  0.12010558029656769,\n",
              "  0.11675590840184988,\n",
              "  0.11371284181178684,\n",
              "  0.11013143573717404,\n",
              "  0.1075243863901357,\n",
              "  0.10419286979782966,\n",
              "  0.10961638249483587,\n",
              "  0.09778666661845313,\n",
              "  0.09583109470358031,\n",
              "  0.09459021919837562,\n",
              "  0.09179557988079645,\n",
              "  0.08991102660642303,\n",
              "  0.08756189670507199,\n",
              "  0.08541964699504195,\n",
              "  0.0829613200759375,\n",
              "  0.08074136524324349,\n",
              "  0.07920727577047108,\n",
              "  0.07697737513370412,\n",
              "  0.0753729007470565,\n",
              "  0.07351873160797208,\n",
              "  0.07251052630524482,\n",
              "  0.07038084967696111,\n",
              "  0.06892894291215473,\n",
              "  0.06748521960871194,\n",
              "  0.06643989495265441,\n",
              "  0.06475451943801723,\n",
              "  0.06376133218247404,\n",
              "  0.06274024730942156,\n",
              "  0.06147409663085015,\n",
              "  0.060475144401780166,\n",
              "  0.0594091140214474,\n",
              "  0.05859340213265898,\n",
              "  0.05770886611981204,\n",
              "  0.05873666495405218,\n",
              "  0.05549039102850422,\n",
              "  0.05519866908643408,\n",
              "  0.05436327612848692,\n",
              "  0.05406563385893794,\n",
              "  0.05292724322621113,\n",
              "  0.05244507819520957,\n",
              "  0.05285052322251822,\n",
              "  0.05200746125378062,\n",
              "  0.051306821218955474,\n",
              "  0.0502657447023631,\n",
              "  0.04984785213158549]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHKk1sM1GiVg",
        "colab_type": "code",
        "outputId": "35d39507-bb81-48c9-c21a-d654ac863903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "for seq_index in range(2):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 5]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: 하르방 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 할망 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLt1JGEtHGQK",
        "colab_type": "code",
        "outputId": "f13c1c8a-ce68-4f6a-d43f-5a4e9e25c703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoded_sentence[1:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'감물'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkuN6RnpGPHz",
        "colab_type": "code",
        "outputId": "dd320e72-d6f3-4351-e0da-33e89b69818b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 10]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: 하르방 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 할망 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 아방 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 어멍 \n",
            "Decoded sentence:  감물들인인옷\n",
            "\n",
            "-\n",
            "Input sentence: 비바리 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 괸당 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 걸바시 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 넹바리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 다슴아돌 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 말젯놈 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 소나이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 성님 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 작산 거 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 좀녀 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 촐람생이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 홀아방 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 가달 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 꼴랑지 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 구뚱배기 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 꽝 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 굴레 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 대망생이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 등땡이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 또꼬망 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 모감지 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 베 봉탱이 \n",
            "Decoded sentence:  어 지\n",
            "\n",
            "-\n",
            "Input sentence: 베아지 볼라불라\n",
            "Decoded sentence:  어 지\n",
            "\n",
            "-\n",
            "Input sentence: 상판이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 야게기 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 야굴탁 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 임댕이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 정겡이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 저껭이 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 조금태기 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 좀짐팽이 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 허운데기 \n",
            "Decoded sentence:  잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 허벅다리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 놋 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 간수메 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 개역 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 것 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 괴기 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 바당괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 돗괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 쇠괴기 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 도괴기 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 곤떡 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 곤밥 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 놈삐 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 대사니김치 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 마농 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 마농 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 조배기 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 촐래 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 촘지금 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 짐치 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 촙쏠 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 조팝 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 갈옷 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 갈 적삼 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 갈 중이 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 강알터진 바지 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 게와 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 단취 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 밀랑 페랭이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 보선 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 소중이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 신착 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 찍신 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 좀뱅이 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 등지게 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 고장중이 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 도폭 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 두루막 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 베불레기 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 우장 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 저구리 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 지성귀 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 지서귀 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 쪼께 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 치메 \n",
            "Decoded sentence:  돼지\n",
            "\n",
            "-\n",
            "Input sentence: 건대 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 사모관대 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 시미옷 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 제복 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 망근 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 방립 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 벙것 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 상갓 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 탕근 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 풍뎅이 \n",
            "Decoded sentence:  여\n",
            "\n",
            "-\n",
            "Input sentence: 휘양 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 낭저 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 달리 \n",
            "Decoded sentence:  감물들인 옷\n",
            "\n",
            "-\n",
            "Input sentence: 빈네 \n",
            "Decoded sentence:  여자\n",
            "\n",
            "-\n",
            "Input sentence: 상퉁이 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 얼레기 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 얼레빗 \n",
            "Decoded sentence:  잠잠하다\n",
            "\n",
            "-\n",
            "Input sentence: 쪽도리 \n",
            "Decoded sentence:  바지\n",
            "\n",
            "-\n",
            "Input sentence: 쳉빗 \n",
            "Decoded sentence:  돼지\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}