{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 구조 : 제주방언 tab 표준어\n",
    "# 파일 불러와서 제주방언끼리 / 표준어끼리 나눔 & test, train set 나눔 (여기서 나누나?흠)\n",
    "# 각각 품사 태깅 작업 (표준어는 있는 라이브러리 쓰면 되고 _4가지 다? 일부만?)\n",
    "# 제주어는 따로 작성한 사전 추가해서 태깅 작업\n",
    "=> 토크나이징 된 문서 작성, json 형태로 저장\n",
    "이 때 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input data shape\n",
    "https://blog.pingpong.us/tokenizer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "효과적인 한국어 모델링을 위해서 tokenizer는 매우 중요하고\n",
    "최신의 복잡한 모델을 사용하는 것보다 성능을 더 크게 올릴 수도 있는 요소입니다.\n",
    "\n",
    "공백 기준의 tokenizer\n",
    "형태소 분석기 기반 tokenizer (문제: 형태소 분석이 100% 확실하진 않음, 띄어쓰기 오류, 오타, 신조어에 취약,\n",
    "                     속도가 느림, OOV 새로운 단어 몰랑)\n",
    "Word Piece Model로 대표되는 Byte Pair Encoding (BPE) 기반의 tokenizer\n",
    "(접두사, 접미사가 비교적 규칙적으로 잘 활용되는 영어의 경우 좋은 효과를 보임,\n",
    " 한글의 경우 워낙 변형이 다양하기 때문에 잘 동작하지 않을 수도 있다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "형태소 분석기 기반 _ Mecab\n",
    "BPE 기반 _ SentencePiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from coleections import Counter\n",
    "import cvs\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 5000\n",
    "data_path = 'jeju_final.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 나눠주기 (제주어 tab 표준어로 나뉘어져 있음)\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[:min(num_samples, len(lines)-1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    target_text = '\\t' + target_text.strip() + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 띄어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('가', 0), ('가게', 1), ('가게마씀', 2), ('가곡', 3), ('가그네', 4), ('가노라면', 5), ('가는', 6), ('가능', 7), ('가달', 8), ('가당', 9)]\n",
      "[(0, '가'), (1, '가게'), (2, '가게마씀'), (3, '가곡'), (4, '가그네'), (5, '가노라면'), (6, '가는'), (7, '가능'), (8, '가달'), (9, '가당')]\n",
      "vocabulary size:  1571\n"
     ]
    }
   ],
   "source": [
    "# 형태소분석\n",
    "# 제주어 방언으로 만든 파일 불러와서 사전 만들기 (한번만 하면 됨)\n",
    "jeju_dictionary = dict()\n",
    "with open('jeju_vocab.txt', encoding='utf-8-sig') as f:\n",
    "    for line in f:\n",
    "        line = line.split('\\t')[0]\n",
    "        jeju_dictionary[line] = len(jeju_dictionary)\n",
    "\n",
    "jeju_reverse_dictionary = dict(zip(jeju_dictionary.values(), jeju_dictionary.keys()))\n",
    "\n",
    "# 잘 되었나 확인\n",
    "print(list(jeju_dictionary.items())[:10])\n",
    "print(list(jeju_reverse_dictionary.items())[:10])\n",
    "print('vocabulary size: ', len(jeju_reverse_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No matching overloads found for kr.lucypark.kkma.KkmaInterface.morphAnalyzer(list), options are:\n\tpublic java.util.List kr.lucypark.kkma.KkmaInterface.morphAnalyzer(java.lang.String) throws java.lang.Exception\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-34b969f79a93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#for inline in input_texts:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkkma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_kkma.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, flatten, join)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \"\"\"\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjki\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphAnalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mmorphemes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No matching overloads found for kr.lucypark.kkma.KkmaInterface.morphAnalyzer(list), options are:\n\tpublic java.util.List kr.lucypark.kkma.KkmaInterface.morphAnalyzer(java.lang.String) throws java.lang.Exception\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n"
     ]
    }
   ],
   "source": [
    "# 표준어 토큰화\n",
    "# 품사 태깅\n",
    "# mecab은 윈도우에서 안됨 (맥프로로 돌리장~ 결과는 json으로 저장해서 가져와서 쓰기)\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "#for inline in input_texts:\n",
    "kkma.pos(input_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No matching overloads found for kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(list), options are:\n\tpublic java.lang.String kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(java.lang.String)\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-0e91c82a0601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHannanum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhannanum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHannanum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhannanum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_hannanum.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, ntags, flatten, join)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntags\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjhi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplePos09\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mntags\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjhi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplePos22\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No matching overloads found for kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(list), options are:\n\tpublic java.lang.String kr.lucypark.jhannanum.comm.HannanumInterface.simplePos09(java.lang.String)\n\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:242)\n\tat JPMethod::findOverload(native\\common\\jp_method.cpp:245)\n\tat JPMethod::invoke(native\\common\\jp_method.cpp:253)\n\tat PyJPMethod::__call__(native\\python\\pyjp_method.cpp:142)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "hannanum.pos(input_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
